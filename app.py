"""
æ ªå¼ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†Webã‚¢ãƒ—ãƒª
ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from typing import Optional, Dict, Any, List
import logging
from datetime import datetime, timezone, timedelta
import os
import sys
from dotenv import load_dotenv

# æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®è¨­å®šï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
try:
    if sys.platform == "win32":
        import locale
        # Windowsã§ã®ãƒ­ã‚±ãƒ¼ãƒ«è¨­å®š
        try:
            locale.setlocale(locale.LC_ALL, 'Japanese_Japan.UTF-8')
        except:
            try:
                locale.setlocale(locale.LC_ALL, 'ja_JP.UTF-8')
            except:
                pass  # ãƒ­ã‚±ãƒ¼ãƒ«è¨­å®šã«å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ
except Exception:
    pass

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# APIè¨­å®š - è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å¾Œã§è¡¨ç¤º
# Gemini APIè¨­å®š
GEMINI_AVAILABLE = False
GEMINI_ERROR_MSG = None
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    if not os.getenv('GEMINI_API_KEY'):
        GEMINI_AVAILABLE = False
        GEMINI_ERROR_MSG = "Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«GEMINI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
except ImportError as e:
    GEMINI_AVAILABLE = False
    GEMINI_ERROR_MSG = f"Google Generative AIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:\nä»®æƒ³ç’°å¢ƒå†…ã§: pip install google-generativeai\nã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}"
except Exception as e:
    GEMINI_AVAILABLE = False
    GEMINI_ERROR_MSG = f"Gemini APIè¨­å®šã‚¨ãƒ©ãƒ¼: {str(e)}"

# Google Search APIè¨­å®š
GOOGLE_SEARCH_AVAILABLE = False
GOOGLE_SEARCH_ERROR_MSG = None
try:
    from googleapiclient.discovery import build
    GOOGLE_SEARCH_AVAILABLE = True
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    if not os.getenv('GOOGLE_API_KEY') or not os.getenv('GOOGLE_SEARCH_ENGINE_ID'):
        GOOGLE_SEARCH_AVAILABLE = False
        GOOGLE_SEARCH_ERROR_MSG = "Google Search APIã®è¨­å®šãŒä¸å®Œå…¨ã§ã™ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«GOOGLE_API_KEYã¨GOOGLE_SEARCH_ENGINE_IDã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
except ImportError as e:
    GOOGLE_SEARCH_AVAILABLE = False
    GOOGLE_SEARCH_ERROR_MSG = f"Google APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:\nä»®æƒ³ç’°å¢ƒå†…ã§: pip install google-api-python-client\nã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}"

# BeautifulSoupè¨­å®š
SCRAPING_AVAILABLE = False
SCRAPING_ERROR_MSG = None
try:
    from bs4 import BeautifulSoup
    import requests
    SCRAPING_AVAILABLE = True
except ImportError as e:
    SCRAPING_AVAILABLE = False
    SCRAPING_ERROR_MSG = f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:\nä»®æƒ³ç’°å¢ƒå†…ã§: pip install beautifulsoup4 requests\nã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}"

# å…¨æ©Ÿèƒ½ã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
REPORT_GENERATION_AVAILABLE = GEMINI_AVAILABLE and GOOGLE_SEARCH_AVAILABLE and SCRAPING_AVAILABLE

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from modules.data_loader import load_portfolio_data, validate_portfolio_data, display_data_summary
from modules.data_manager import get_data_manager
from modules.data_adapter import create_data_adapter, validate_data_bundle
from modules.price_fetcher import (
    cached_get_current_prices, cached_get_exchange_rates, 
    determine_currency_from_ticker, convert_to_jpy, get_historical_data, get_stock_chart_data
)
from modules.pnl_calculator import (
    calculate_portfolio_pnl, calculate_portfolio_summary,
    calculate_sector_allocation_by_region, calculate_sector_allocation, calculate_performance_metrics,
    calculate_portfolio_valuation_metrics, get_etf_benchmark_data
)
from modules.country_fetcher import cached_get_multiple_ticker_countries, cached_get_multiple_ticker_info, cached_get_multiple_ticker_complete_info
from modules.risk_calculator import (
    calculate_portfolio_risk, calculate_var_cvar, stress_test_scenario
)
from modules.visualizer import (
    create_pnl_chart, create_allocation_pie, create_correlation_heatmap,
    create_var_distribution, create_performance_summary_chart, create_sector_allocation_chart,
    create_price_history_chart, create_stock_candlestick_chart, create_stock_line_chart,
    create_factor_beta_chart, create_rolling_beta_chart, create_factor_contribution_chart
)
from utils.currency_mapper import get_currency_mapping, get_market_info
from utils.helpers import (
    format_currency, format_percentage, display_error_message,
    display_success_message, display_warning_message, show_loading_spinner,
    calculate_returns
)
from modules.factor_analysis import (
    get_fama_french_factors, calculate_portfolio_returns_robust, perform_factor_regression,
    calculate_rolling_betas, calculate_factor_contributions, get_factor_interpretation
)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main_dashboard():
    """ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    st.set_page_config(
        page_title="ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # APIè¨­å®šã®è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    if GEMINI_ERROR_MSG or GOOGLE_SEARCH_ERROR_MSG or SCRAPING_ERROR_MSG:
        st.error("ğŸš¨ é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æä»˜ãï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®è¨­å®šãŒå¿…è¦ã§ã™ï¼š")
        
        if GEMINI_ERROR_MSG:
            st.error(f"**Gemini API**: {GEMINI_ERROR_MSG}")
        if GOOGLE_SEARCH_ERROR_MSG:
            st.error(f"**Google Search API**: {GOOGLE_SEARCH_ERROR_MSG}")
        if SCRAPING_ERROR_MSG:
            st.error(f"**ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**: {SCRAPING_ERROR_MSG}")
            
        with st.expander("ğŸ“‹ è©³ç´°ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ã‚’è¡¨ç¤º"):
            st.markdown("""
            ### ä»®æƒ³ç’°å¢ƒã§ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †
            
            **1. ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ:**
            ```bash
            # Windows
            venv\\Scripts\\activate
            
            # Linux/Mac
            source venv/bin/activate
            ```
            
            **2. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:**
            ```bash
            pip install --upgrade pip
            pip install google-generativeai
            pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib
            pip install beautifulsoup4 requests
            pip install -r requirements.txt --upgrade
            ```
            
            **3. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª:**
            ```bash
            python -c "import google.generativeai; print('âœ“ Gemini API ready')"
            python -c "from googleapiclient.discovery import build; print('âœ“ Google Search API ready')"
            python -c "from bs4 import BeautifulSoup; print('âœ“ Scraping libraries ready')"
            ```
            
            **4. .envãƒ•ã‚¡ã‚¤ãƒ«ã«APIã‚­ãƒ¼ã‚’è¨­å®š:**
            ```env
            GOOGLE_API_KEY=your-google-cloud-api-key
            GOOGLE_SEARCH_ENGINE_ID=your-search-engine-id
            GEMINI_API_KEY=your-gemini-api-key
            ```
            
            è©³ç´°ã¯ `INSTALL_GUIDE.md` ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
            """)
        
        st.info("ğŸ’¡ ä¸Šè¨˜ã®è¨­å®šãŒå®Œäº†ã™ã‚‹ã¾ã§ã€å¾“æ¥ã®ChatGPTæ©Ÿèƒ½ï¼ˆè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰ã¾ãŸã¯åŸºæœ¬çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã®ã¿ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
    if 'current_tab' not in st.session_state:
        st.session_state.current_tab = 0
    if 'uploaded_data' not in st.session_state:
        st.session_state.uploaded_data = None
    if 'portfolio_df' not in st.session_state:
        st.session_state.portfolio_df = None
    
    st.title("ğŸ“Š æ ªå¼ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    with st.sidebar:
        st.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        
        # portfolio_filesãƒ•ã‚©ãƒ«ãƒ€å†…ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡º
        portfolio_files_dir = "portfolio_files"
        detected_files = []
        selected_file = None
        
        if os.path.exists(portfolio_files_dir):
            detected_files = [f for f in os.listdir(portfolio_files_dir) if f.endswith('.csv')]
            
        if detected_files:
            st.subheader("ğŸ“‚ æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«")
            selected_file_name = st.selectbox(
                "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ:",
                ["é¸æŠã—ã¦ãã ã•ã„"] + detected_files,
                help="portfolio_filesãƒ•ã‚©ãƒ«ãƒ€å†…ã®CSVãƒ•ã‚¡ã‚¤ãƒ«"
            )
            
            if selected_file_name != "é¸æŠã—ã¦ãã ã•ã„":
                selected_file_path = os.path.join(portfolio_files_dir, selected_file_name)
                try:
                    with open(selected_file_path, 'rb') as f:
                        selected_file = f.read()
                    st.success(f"ãƒ•ã‚¡ã‚¤ãƒ« '{selected_file_name}' ãŒé¸æŠã•ã‚Œã¾ã—ãŸï¼")
                    
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                    try:
                        preview_df = pd.read_csv(selected_file_path)
                        st.write("**ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:**")
                        st.dataframe(preview_df.head(), use_container_width=True)
                    except:
                        pass
                except Exception as e:
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            st.markdown("---")
        
        uploaded_file = st.file_uploader(
            "ã¾ãŸã¯æ–°ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['csv'],
            help="ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: Ticker, Shares, AvgCostJPY"
        )
        
        if uploaded_file:
            st.success("ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸï¼")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            if st.session_state.uploaded_data != uploaded_file.getvalue():
                st.session_state.uploaded_data = uploaded_file.getvalue()
                st.session_state.portfolio_df = None  # ãƒ‡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
            
            # ç°¡æ˜“ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            try:
                preview_df = pd.read_csv(uploaded_file)
                uploaded_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
                st.write("**ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:**")
                st.dataframe(preview_df.head(), use_container_width=True)
            except:
                pass
        
        # selected_fileã®å ´åˆã‚‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ç®¡ç†
        elif selected_file:
            if st.session_state.uploaded_data != selected_file:
                st.session_state.uploaded_data = selected_file
                st.session_state.portfolio_df = None  # ãƒ‡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
            
        st.markdown("---")
        st.subheader("ğŸ“‹ CSVãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼")
        st.code("""
Ticker,Shares,AvgCostJPY
AAPL,100,15000
MSFT,50,25000
7203.T,1000,800
        """)
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    current_file = uploaded_file or selected_file
    
    if current_file is not None:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‹æ–°è¦å‡¦ç†
        if st.session_state.portfolio_df is None:
            if uploaded_file:
                portfolio_df = validate_and_load_portfolio_data(uploaded_file)
            else:
                # selected_fileã®å ´åˆã€BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                import io
                file_like = io.BytesIO(selected_file)
                portfolio_df = validate_and_load_portfolio_data(file_like)
            
            if portfolio_df is not None:
                st.session_state.portfolio_df = portfolio_df
        else:
            portfolio_df = st.session_state.portfolio_df
        
        if portfolio_df is not None:
            display_portfolio_dashboard(portfolio_df)
    else:
        display_welcome_page()


def validate_and_load_portfolio_data(uploaded_file) -> Optional[pd.DataFrame]:
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿"""
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        portfolio_df = load_portfolio_data(uploaded_file)
        
        if portfolio_df is not None:
            display_success_message(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(portfolio_df)}éŠ˜æŸ„ï¼‰")
            return portfolio_df
        else:
            return None
            
    except Exception as e:
        display_error_message(e, "ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        return None


def display_portfolio_dashboard(portfolio_df: pd.DataFrame):
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¡¨ç¤º"""
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
        display_data_summary(portfolio_df)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ãƒ‡ãƒ¼ã‚¿ãƒãƒ³ãƒ‰ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        tickers = portfolio_df['Ticker'].tolist()
        tickers_key = tuple(sorted(tickers))
        
        if ('data_bundle' not in st.session_state or 
            st.session_state.get('data_tickers') != tickers_key):
            
            with show_loading_spinner("å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å–å¾—ä¸­ï¼ˆéå»5å¹´åˆ†ã®ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰..."):
                # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨ã—ã¦å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å–å¾—
                data_manager = get_data_manager()
                data_bundle = data_manager.load_portfolio_data(portfolio_df)
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                st.session_state.data_bundle = data_bundle
                st.session_state.data_tickers = tickers_key
                
                # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’ä½œæˆ
                st.session_state.data_adapter = create_data_adapter(data_bundle)
                
                # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸã®ç¢ºèª
                factor_data = data_bundle.get('factor_data', {})
                if factor_data:
                    for key, df in factor_data.items():
                        if isinstance(df, pd.DataFrame) and not df.empty:
                            factor_start = df.index.min().strftime('%Y-%m-%d') if hasattr(df.index, 'strftime') else str(df.index.min())
                            factor_end = df.index.max().strftime('%Y-%m-%d') if hasattr(df.index, 'strftime') else str(df.index.max())
                            st.toast(f"ğŸ¯ éå»5å¹´åˆ†Fama-Frenchãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†ï¼({factor_start}ï½{factor_end}, {len(df):,}æ—¥åˆ†)", icon="âœ…")
                            break
        else:
            # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            data_bundle = st.session_state.data_bundle
            data_adapter = st.session_state.data_adapter
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªã®è¡¨ç¤º
        if 'data_adapter' in st.session_state:
            data_adapter = st.session_state.data_adapter
            quality_summary = data_adapter.get_data_freshness_summary()
            st.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ª: {quality_summary}")
        
        # æç›Šè¨ˆç®—ï¼ˆã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’ä½¿ç”¨ï¼‰
        if 'data_adapter' not in st.session_state:
            display_warning_message("ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
            return
        
        data_adapter = st.session_state.data_adapter
        
        # ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‹ã‚‰å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        current_prices = data_adapter.get_multiple_current_prices(tickers)
        exchange_rates = data_adapter.get_exchange_rates()
        currency_mapping = data_adapter.get_currency_mapping()
        
        # æç›Šè¨ˆç®—
        pnl_df = calculate_portfolio_pnl(
            portfolio_df, current_prices, exchange_rates, currency_mapping
        )
        
        if pnl_df.empty:
            display_warning_message("æç›Šè¨ˆç®—ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã—ã°ã‚‰ãå¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚µãƒãƒªãƒ¼ã‚’è¨ˆç®—
        portfolio_summary = calculate_portfolio_summary(pnl_df)
        
        # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        display_portfolio_metrics(portfolio_summary)
        
        st.markdown("---")
        
        # ã‚¿ãƒ–ã«ã‚ˆã‚‹è©³ç´°è¡¨ç¤º
        tab_names = [
            "ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", "âš ï¸ ãƒªã‚¹ã‚¯åˆ†æ", "ğŸŒ é…åˆ†åˆ†æ", 
            "ğŸ’° ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³", "ğŸ“° é‹ç”¨å ±å‘Š", "ğŸ“Š æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆ", "ğŸ” è©³ç´°ãƒ‡ãƒ¼ã‚¿"
        ]
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼ã§ã‚¿ãƒ–ã‚’ç®¡ç†
        selected_tab = st.radio(
            "è¡¨ç¤ºã™ã‚‹ã‚¿ãƒ–ã‚’é¸æŠ:",
            options=tab_names,
            index=st.session_state.current_tab,
            horizontal=True,
            key="tab_selector"
        )
        
        # ç¾åœ¨ã®ã‚¿ãƒ–ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°
        if selected_tab:
            st.session_state.current_tab = tab_names.index(selected_tab)
        
        st.markdown("---")
        
        # é¸æŠã•ã‚ŒãŸã‚¿ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤º
        if selected_tab == "ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹":
            display_performance_analysis(pnl_df, portfolio_summary)
        elif selected_tab == "âš ï¸ ãƒªã‚¹ã‚¯åˆ†æ":
            display_risk_analysis(pnl_df, tickers, portfolio_df)
        elif selected_tab == "ğŸŒ é…åˆ†åˆ†æ":
            display_allocation_analysis(pnl_df, tickers)
        elif selected_tab == "ğŸ’° ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³":
            display_valuation_analysis(pnl_df, tickers)
        elif selected_tab == "ğŸ“° é‹ç”¨å ±å‘Š":
            display_investment_report(pnl_df, tickers)
        elif selected_tab == "ğŸ“Š æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆ":
            display_stock_charts(tickers)
        elif selected_tab == "ğŸ” è©³ç´°ãƒ‡ãƒ¼ã‚¿":
            display_detailed_data(pnl_df, portfolio_df, tickers)
            
    except Exception as e:
        display_error_message(e, "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")


def display_portfolio_metrics(summary: Dict[str, float]):
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º"""
    if not summary:
        return
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ç·è©•ä¾¡é¡",
            value=format_currency(summary.get('total_current_value_jpy', 0)),
            delta=format_currency(summary.get('total_pnl_amount_jpy', 0))
        )
    
    with col2:
        st.metric(
            label="ç·æç›Šç‡",
            value=format_percentage(summary.get('overall_pnl_percentage', 0)),
            delta=f"{summary.get('profitable_positions', 0)}å‹/{summary.get('losing_positions', 0)}æ•—"
        )
    
    with col3:
        st.metric(
            label="å‹ç‡",
            value=format_percentage(summary.get('win_rate', 0)),
            delta=f"å¹³å‡ãƒã‚¸ã‚·ãƒ§ãƒ³: {format_currency(summary.get('average_position_size', 0))}"
        )
    
    with col4:
        best_ticker = summary.get('max_gain_ticker', '')
        worst_ticker = summary.get('max_loss_ticker', '')
        st.metric(
            label="æœ€é«˜/æœ€ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
            value=f"{best_ticker}: {format_percentage(summary.get('max_gain_percentage', 0))}",
            delta=f"{worst_ticker}: {format_percentage(summary.get('max_loss_percentage', 0))}"
        )


def display_performance_analysis(pnl_df: pd.DataFrame, summary: Dict[str, float]):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã®è¡¨ç¤º"""
    st.subheader("ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æç›Šãƒãƒ£ãƒ¼ãƒˆ
        pnl_chart = create_pnl_chart(pnl_df)
        st.plotly_chart(pnl_chart, use_container_width=True)
    
    with col2:
        # è³‡ç”£é…åˆ†ãƒãƒ£ãƒ¼ãƒˆ
        allocation_chart = create_allocation_pie(pnl_df)
        st.plotly_chart(allocation_chart, use_container_width=True)
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼
    if summary:
        performance_chart = create_performance_summary_chart(summary)
        st.plotly_chart(performance_chart, use_container_width=True)


def display_risk_analysis(pnl_df: pd.DataFrame, tickers: list, portfolio_df: pd.DataFrame):
    """ãƒªã‚¹ã‚¯åˆ†æã®è¡¨ç¤º"""
    st.subheader("âš ï¸ ãƒªã‚¹ã‚¯åˆ†æ")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ãƒªã‚¹ã‚¯åˆ†æè¨­å®šã‚’ç®¡ç†
    if 'risk_analysis_period' not in st.session_state:
        st.session_state.risk_analysis_period = "1y"
    if 'risk_time_scale' not in st.session_state:
        st.session_state.risk_time_scale = "æ—¥æ¬¡"
    
    # è¨­å®šUI
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        st.write("åˆ†ææœŸé–“ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š")
    with col2:
        analysis_period = st.selectbox(
            "ãƒ‡ãƒ¼ã‚¿æœŸé–“",
            options=["1mo", "3mo", "6mo", "ytd", "1y", "2y", "5y"],
            index=["1mo", "3mo", "6mo", "ytd", "1y", "2y", "5y"].index(st.session_state.risk_analysis_period),
            help="ç›¸é–¢åˆ†æãƒ»ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—ã«ä½¿ç”¨ã™ã‚‹éå»ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“",
            key="risk_analysis_period_selector"
        )
        st.session_state.risk_analysis_period = analysis_period
    
    with col3:
        time_scale = st.selectbox(
            "ãƒªã‚¹ã‚¯æ™‚é–“è»¸",
            options=["æ—¥æ¬¡", "æœˆæ¬¡", "å¹´æ¬¡"],
            index=["æ—¥æ¬¡", "æœˆæ¬¡", "å¹´æ¬¡"].index(st.session_state.risk_time_scale),
            help="VaR/CVaRã¨ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã®è¡¨ç¤ºæ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«",
            key="risk_time_scale_selector"
        )
        st.session_state.risk_time_scale = time_scale
    
    # æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›ä¿‚æ•°ã‚’äº‹å‰ã«è¨ˆç®—
    def get_time_scale_factor(scale):
        if scale == "æ—¥æ¬¡":
            return 1, "æ—¥"
        elif scale == "æœˆæ¬¡":
            return np.sqrt(20), "æœˆ"  # 20å–¶æ¥­æ—¥
        elif scale == "å¹´æ¬¡":
            return np.sqrt(252), "å¹´"  # 252å–¶æ¥­æ—¥
        return 1, "æ—¥"
    
    scale_factor, scale_label = get_time_scale_factor(time_scale)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸéå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        data_adapter = st.session_state.get('data_adapter')
        if not data_adapter:
            st.error("ãƒ‡ãƒ¼ã‚¿ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
            return
        
        with show_loading_spinner(f"éå»ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸéå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¿…è¦ãªæœŸé–“ã‚’æŠ½å‡º
            historical_data_dict = data_adapter.get_multiple_historical_data(tickers, period="5y")
            
            # æŒ‡å®šæœŸé–“ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            from datetime import datetime, timedelta
            if analysis_period == "1mo":
                start_date = datetime.now() - timedelta(days=30)
            elif analysis_period == "3mo":
                start_date = datetime.now() - timedelta(days=90)
            elif analysis_period == "6mo":
                start_date = datetime.now() - timedelta(days=180)
            elif analysis_period == "ytd":
                start_date = datetime(datetime.now().year, 1, 1)
            elif analysis_period == "1y":
                start_date = datetime.now() - timedelta(days=365)
            elif analysis_period == "2y":
                start_date = datetime.now() - timedelta(days=730)
            else:  # 5y
                start_date = datetime.now() - timedelta(days=1825)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
            historical_data = pd.DataFrame()
            for ticker in tickers:
                ticker_data = historical_data_dict.get(ticker, pd.DataFrame())
                if not ticker_data.empty:
                    # æŒ‡å®šæœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    ticker_data = ticker_data[ticker_data.index >= start_date]
                    if not ticker_data.empty:
                        historical_data[ticker] = ticker_data['Close']
            
            if historical_data.empty:
                st.warning("æŒ‡å®šæœŸé–“ã®éå»ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return
            
            # ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã‚‹å ´åˆã®è­¦å‘Š
            if len(historical_data) < 20:
                st.warning(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“ãŒçŸ­ã™ãã¾ã™ï¼ˆ{len(historical_data)}æ—¥ï¼‰ã€‚ã‚ˆã‚Šé•·ã„æœŸé–“ã‚’é¸æŠã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
            
            # æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—
            returns_df = pd.DataFrame()
            for ticker in tickers:
                if ticker in historical_data.columns:
                    returns = calculate_returns(historical_data[ticker])
                    if not returns.empty:
                        returns_df[ticker] = returns
            
            if returns_df.empty:
                st.error("ãƒªã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return
            
            st.info(f"ğŸ“Š åˆ†ææœŸé–“: {analysis_period} ({len(returns_df)}å–¶æ¥­æ—¥ã®ãƒ‡ãƒ¼ã‚¿)")
            
            # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªé‡ã¿ã‚’è¨ˆç®—
            total_value = pnl_df['current_value_jpy'].sum()
            weights = (pnl_df['current_value_jpy'] / total_value).values
            
            # ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã‚‹éŠ˜æŸ„ã®ã¿ã§ã‚¦ã‚§ã‚¤ãƒˆã‚’å†è¨ˆç®—
            valid_tickers = [ticker for ticker in tickers if ticker in returns_df.columns]
            valid_pnl = pnl_df[pnl_df['ticker'].isin(valid_tickers)]
            
            if len(valid_tickers) != len(tickers):
                missing_tickers = set(tickers) - set(valid_tickers)
                st.warning(f"ä»¥ä¸‹ã®éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€åˆ†æã‹ã‚‰é™¤å¤–ã•ã‚Œã¾ã™: {', '.join(missing_tickers)}")
            
            if len(valid_tickers) < 2:
                st.error("ç›¸é–¢åˆ†æã«ã¯å°‘ãªãã¨ã‚‚2éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚")
                return
            
            # æœ‰åŠ¹ãªéŠ˜æŸ„ã®ã‚¦ã‚§ã‚¤ãƒˆã‚’å†è¨ˆç®—
            valid_total_value = valid_pnl['current_value_jpy'].sum()
            valid_weights = (valid_pnl['current_value_jpy'] / valid_total_value).values
            
            # ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—
            risk_metrics = calculate_portfolio_risk(returns_df[valid_tickers], valid_weights)
            
            if risk_metrics:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ“Š ãƒªã‚¹ã‚¯æŒ‡æ¨™")
                    portfolio_vol_scaled = risk_metrics.get('portfolio_volatility', 0) * scale_factor
                    st.metric(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ{scale_label}æ¬¡ï¼‰", 
                             format_percentage(portfolio_vol_scaled * 100))
                    st.metric("å¹³å‡ç›¸é–¢", 
                             f"{risk_metrics.get('average_correlation', 0):.3f}")
                    st.metric("åˆ†æ•£åŠ¹æœ", 
                             f"{risk_metrics.get('diversification_ratio', 1):.2f}x")
                    
                    # å€‹åˆ¥éŠ˜æŸ„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®è¡¨ç¤º
                    with st.expander(f"å€‹åˆ¥éŠ˜æŸ„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ{scale_label}æ¬¡ï¼‰"):
                        individual_vols = risk_metrics.get('individual_volatilities', pd.Series())
                        for ticker, vol in individual_vols.items():
                            vol_scaled = vol * scale_factor
                            st.write(f"**{ticker}**: {format_percentage(vol_scaled * 100)}")
                
                with col2:
                    # ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
                    if 'correlation_matrix' in risk_metrics:
                        corr_chart = create_correlation_heatmap(risk_metrics['correlation_matrix'])
                        st.plotly_chart(corr_chart, use_container_width=True)
            
            # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—
            portfolio_returns = (returns_df[valid_tickers] * valid_weights).sum(axis=1)
            
            # VaR/CVaRè¨ˆç®—
            var_metrics = calculate_var_cvar(pd.Series(portfolio_returns))
            
            if var_metrics:
                st.subheader(f"ğŸ“‰ VaR/CVaRåˆ†æï¼ˆ{scale_label}æ¬¡ï¼‰")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    var_95_scaled = var_metrics.get('VaR_95', 0) * scale_factor
                    st.metric(f"VaR (95%)", format_percentage(var_95_scaled * 100))
                
                with col2:
                    cvar_95_scaled = var_metrics.get('CVaR_95', 0) * scale_factor
                    st.metric(f"CVaR (95%)", format_percentage(cvar_95_scaled * 100))
                
                with col3:
                    var_99_scaled = var_metrics.get('VaR_99', 0) * scale_factor
                    st.metric(f"VaR (99%)", format_percentage(var_99_scaled * 100))
                
                with col4:
                    daily_vol = portfolio_returns.std()
                    scaled_vol = daily_vol * scale_factor
                    st.metric(f"{scale_label}ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£", format_percentage(scaled_vol * 100))
                
                # VaRåˆ†å¸ƒãƒãƒ£ãƒ¼ãƒˆï¼ˆæ™‚é–“è»¸ã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
                var_chart = create_var_distribution(pd.Series(portfolio_returns), var_metrics, scale_factor, scale_label)
                st.plotly_chart(var_chart, use_container_width=True)
                
                # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
                st.subheader("ğŸš¨ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ")
                stress_results = stress_test_scenario(returns_df[valid_tickers], valid_weights, 
                                                     stress_factor=1.5, correlation_shock=0.8)
                
                if stress_results:
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        normal_vol = stress_results.get('normal_portfolio_vol', 0)
                        normal_vol_scaled = normal_vol * scale_factor
                        st.metric(f"é€šå¸¸æ™‚ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ{scale_label}æ¬¡ï¼‰", format_percentage(normal_vol_scaled * 100))
                    
                    with col2:
                        stressed_vol = stress_results.get('stressed_portfolio_vol', 0)
                        stressed_vol_scaled = stressed_vol * scale_factor
                        st.metric(f"ã‚¹ãƒˆãƒ¬ã‚¹æ™‚ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ{scale_label}æ¬¡ï¼‰", format_percentage(stressed_vol_scaled * 100))
                    
                    with col3:
                        stress_multiplier = stress_results.get('stress_multiplier', 1)
                        st.metric("ã‚¹ãƒˆãƒ¬ã‚¹å€ç‡", f"{stress_multiplier:.2f}x")
                    
                    with col4:
                        # ã‚¹ãƒˆãƒ¬ã‚¹æ™‚ã®æƒ³å®šæå¤±ï¼ˆ95%ä¿¡é ¼åŒºé–“ã€ç´„2æ¨™æº–åå·®ï¼‰
                        stress_loss_95 = -stressed_vol_scaled * 1.96  # è² ã®å€¤ã¨ã—ã¦è¡¨ç¤º
                        st.metric(f"æƒ³å®šæœ€å¤§æå¤± 95%ï¼ˆ{scale_label}æ¬¡ï¼‰", format_percentage(stress_loss_95 * 100))
                    
                    # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆè©³ç´°
                    with st.expander("ğŸ” ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆè©³ç´°"):
                        st.write("**ã‚¹ãƒˆãƒ¬ã‚¹æ¡ä»¶:**")
                        st.write(f"- ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¢—åŠ å€ç‡: {stress_results.get('stress_factor', 1.5):.1f}å€")
                        st.write(f"- ã‚¹ãƒˆãƒ¬ã‚¹æ™‚ç›¸é–¢ä¿‚æ•°: {stress_results.get('correlation_shock', 0.8):.1f}")
                        st.write(f"- é€šå¸¸æ™‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå¹´ç‡ï¼‰: {format_percentage(normal_vol * 100)}")
                        st.write(f"- ã‚¹ãƒˆãƒ¬ã‚¹æ™‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå¹´ç‡ï¼‰: {format_percentage(stressed_vol * 100)}")
                        
                        st.write("**æƒ³å®šæå¤±ã‚·ãƒŠãƒªã‚ªï¼ˆã‚¹ãƒˆãƒ¬ã‚¹æ™‚ï¼‰:**")
                        scenarios = [
                            ("68%ä¿¡é ¼åŒºé–“ï¼ˆ1Ïƒï¼‰", -stressed_vol_scaled * 1.0, "ç´„68%ã®ç¢ºç‡ã§æå¤±ãŒã“ã®ç¯„å›²å†…"),
                            ("95%ä¿¡é ¼åŒºé–“ï¼ˆ1.96Ïƒï¼‰", -stressed_vol_scaled * 1.96, "ç´„95%ã®ç¢ºç‡ã§æå¤±ãŒã“ã®ç¯„å›²å†…"),
                            ("99%ä¿¡é ¼åŒºé–“ï¼ˆ2.58Ïƒï¼‰", -stressed_vol_scaled * 2.58, "ç´„99%ã®ç¢ºç‡ã§æå¤±ãŒã“ã®ç¯„å›²å†…"),
                            ("99.7%ä¿¡é ¼åŒºé–“ï¼ˆ3Ïƒï¼‰", -stressed_vol_scaled * 3.0, "ç´„99.7%ã®ç¢ºç‡ã§æå¤±ãŒã“ã®ç¯„å›²å†…")
                        ]
                        
                        for scenario_name, loss_pct, description in scenarios:
                            st.write(f"- **{scenario_name}**: {format_percentage(loss_pct * 100)} ({description})")
                
                # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆ†æ
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.subheader("ğŸ“Š ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆ†æ")
                with col2:
                    if st.button("â“ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æã«ã¤ã„ã¦", key="factor_help_button"):
                        st.session_state.show_factor_help = not st.session_state.get('show_factor_help', False)
                
                # ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
                if st.session_state.get('show_factor_help', False):
                    with st.expander("ğŸ“š ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æã®è©³ç´°è§£èª¬", expanded=True):
                        st.markdown("""
                        ## ğŸ¯ **Fama-French 5ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ + Momentumãƒ¢ãƒ‡ãƒ«ã¨ã¯**
                        
                        ãƒãƒ¼ãƒ™ãƒ«çµŒæ¸ˆå­¦è³å—è³ã®ãƒ¦ãƒ¼ã‚¸ãƒ³ãƒ»ãƒ•ã‚¡ãƒ¼ãƒæ•™æˆã‚‰ãŒé–‹ç™ºã—ãŸã€æ ªå¼ãƒªã‚¿ãƒ¼ãƒ³ã‚’èª¬æ˜ã™ã‚‹ä»£è¡¨çš„ãªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
                        ã‚ãªãŸã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãŒã€Œã©ã‚“ãªæŠ•è³‡ã‚¹ã‚¿ã‚¤ãƒ«ã€ãªã®ã‹ã‚’æ•°å€¤ã§æ˜ç¢ºã«ç¤ºã—ã¾ã™ã€‚
                        
                        ---
                        
                        ## ğŸ“Š **å„ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®æ„å‘³**
                        
                        ### ğŸ”µ **å¸‚å ´ãƒ—ãƒ¬ãƒŸã‚¢ãƒ  (Mkt-RF)**
                        - **ãƒ™ãƒ¼ã‚¿ > 1.0**: ğŸ“ˆ **æ”»æ’ƒçš„** - å¸‚å ´ã‚ˆã‚Šå¤§ããå‹•ãï¼ˆãƒã‚¤ãƒªã‚¹ã‚¯ãƒ»ãƒã‚¤ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
                        - **ãƒ™ãƒ¼ã‚¿ < 1.0**: ğŸ›¡ï¸ **å®ˆå‚™çš„** - å¸‚å ´ã‚ˆã‚Šç©ã‚„ã‹ã«å‹•ãï¼ˆãƒ­ãƒ¼ãƒªã‚¹ã‚¯ãƒ»ãƒ­ãƒ¼ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
                        - **ãƒ™ãƒ¼ã‚¿ â‰ˆ 1.0**: âš–ï¸ **å¸‚å ´ä¸¦ã¿** - å¸‚å ´å…¨ä½“ã¨åŒã˜ãƒªã‚¹ã‚¯æ°´æº–
                        
                        ### ğŸŸ  **å°å‹æ ªãƒ—ãƒ¬ãƒŸã‚¢ãƒ  (SMB: Small Minus Big)**
                        - **ãƒ™ãƒ¼ã‚¿ > 0.2**: ğŸ¢ **å°å‹æ ªé‡è¦–** - æˆé•·ä½™åœ°ã®å¤§ãã„å°ã•ãªä¼šç¤¾ã«æŠ•è³‡
                        - **ãƒ™ãƒ¼ã‚¿ < -0.2**: ğŸ¦ **å¤§å‹æ ªé‡è¦–** - å®‰å®šã—ãŸå¤§ä¼æ¥­ã«æŠ•è³‡
                        - **ä¾‹**: æ–°èˆˆä¼æ¥­ vs GAFAM
                        
                        ### ğŸŸ£ **ãƒãƒªãƒ¥ãƒ¼ãƒ—ãƒ¬ãƒŸã‚¢ãƒ  (HML: High Minus Low)**
                        - **ãƒ™ãƒ¼ã‚¿ > 0.2**: ğŸ’ **å‰²å®‰æ ªæŠ•è³‡** - PERã‚„PBRãŒä½ã„ã€Œæ˜ã‚Šå‡ºã—ç‰©ã€ç‹™ã„
                        - **ãƒ™ãƒ¼ã‚¿ < -0.2**: ğŸš€ **æˆé•·æ ªæŠ•è³‡** - é«˜æˆé•·æœŸå¾…ã®ã‚°ãƒ­ãƒ¼ã‚¹æ ªç‹™ã„
                        - **ä¾‹**: ãƒãƒ•ã‚§ãƒƒãƒˆæµãƒãƒªãƒ¥ãƒ¼æŠ•è³‡ vs ãƒ†ã‚¹ãƒ©ç­‰ã®æˆé•·æ ªæŠ•è³‡
                        
                        ### ğŸŸ¢ **åç›Šæ€§ãƒ—ãƒ¬ãƒŸã‚¢ãƒ  (RMW: Robust Minus Weak)**
                        - **ãƒ™ãƒ¼ã‚¿ > 0.2**: ğŸ’° **å„ªè‰¯ä¼æ¥­é‡è¦–** - ROEãŒé«˜ãåˆ©ç›Šã‚’å®‰å®šçš„ã«å‡ºã™ä¼šç¤¾
                        - **ãƒ™ãƒ¼ã‚¿ < -0.2**: ğŸ¯ **æˆé•·æŠ•è³‡** - ç¾åœ¨ã¯åˆ©ç›ŠãŒå°‘ãªãã¦ã‚‚å°†æ¥æ€§é‡è¦–
                        - **ä¾‹**: é…å½“è²´æ—éŠ˜æŸ„ vs ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—
                        
                        ### ğŸ”´ **æŠ•è³‡ãƒ—ãƒ¬ãƒŸã‚¢ãƒ  (CMA: Conservative Minus Aggressive)**
                        - **ãƒ™ãƒ¼ã‚¿ > 0.2**: ğŸ›ï¸ **å …å®ŸçµŒå–¶é‡è¦–** - è¨­å‚™æŠ•è³‡ã‚’æŠ‘ãˆã¦åˆ©ç›Šé‡è¦–ã®ä¼šç¤¾
                        - **ãƒ™ãƒ¼ã‚¿ < -0.2**: ğŸš **ç©æ¥µæŠ•è³‡é‡è¦–** - å°†æ¥ã®ãŸã‚ã«å¤§èƒ†ã«æŠ•è³‡ã™ã‚‹ä¼šç¤¾
                        - **ä¾‹**: æˆç†Ÿä¼æ¥­ vs R&Dé›†ç´„ä¼æ¥­
                        
                        ### âš¡ **ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãƒ—ãƒ¬ãƒŸã‚¢ãƒ  (Mom)**
                        - **ãƒ™ãƒ¼ã‚¿ > 0.2**: ğŸ“ˆ **ãƒˆãƒ¬ãƒ³ãƒ‰è¿½éš** - ä¸Šæ˜‡ã—ã¦ã„ã‚‹æ ªã¯ã¾ã ä¸ŠãŒã‚‹
                        - **ãƒ™ãƒ¼ã‚¿ < -0.2**: â†©ï¸ **é€†å¼µã‚ŠæŠ•è³‡** - ä¸‹è½ã—ãŸæ ªã®åç™ºã‚’ç‹™ã†
                        - **ä¾‹**: å‹¢ã„ã®ã‚ã‚‹éŠ˜æŸ„è¿½éš vs å‰²å®‰æ”¾ç½®éŠ˜æŸ„ç‹™ã„
                        
                        ---
                        
                        ## ğŸ“¡ **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¨è¨ˆç®—æ–¹æ³•**
                        
                        ### **ãƒ‡ãƒ¼ã‚¿æä¾›å…ƒ**
                        - **Fama-French Data Library** (Kenneth R. Frenchæ•™æˆã®Webã‚µã‚¤ãƒˆ)
                        - ãƒ€ãƒ¼ãƒˆãƒã‚¹å¤§å­¦ã‚¿ãƒƒã‚¯ãƒ»ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»ã‚ªãƒ–ãƒ»ãƒ“ã‚¸ãƒã‚¹
                        - **URL**: https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html
                        
                        ### **è¨ˆç®—ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹**
                        - **å¯¾è±¡å¸‚å ´**: ğŸ‡ºğŸ‡¸ **ç±³å›½æ ªå¼å¸‚å ´**
                        - **å¯¾è±¡éŠ˜æŸ„**: NYSEã€NASDAQã€AMEXä¸Šå ´ã®æ™®é€šæ ª
                        - **é™¤å¤–éŠ˜æŸ„**: REITã€ADRã€ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚¨ãƒ³ãƒ‰ãƒ»ãƒ•ã‚¡ãƒ³ãƒ‰ç­‰
                        - **æ›´æ–°é »åº¦**: æ—¥æ¬¡æ›´æ–°
                        - **æ­´å²**: 1926å¹´ã‹ã‚‰ç¾åœ¨ã¾ã§ï¼ˆç´„100å¹´ã®å®Ÿç¸¾ï¼‰
                        
                        ### **ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼æ§‹ç¯‰æ–¹æ³•**
                        1. **SMB**: æ™‚ä¾¡ç·é¡ã§å°å‹/å¤§å‹ã«åˆ†é¡ â†’ å°å‹æ ªãƒªã‚¿ãƒ¼ãƒ³ - å¤§å‹æ ªãƒªã‚¿ãƒ¼ãƒ³
                        2. **HML**: PBRã§å‰²å®‰/å‰²é«˜ã«åˆ†é¡ â†’ å‰²å®‰æ ªãƒªã‚¿ãƒ¼ãƒ³ - å‰²é«˜æ ªãƒªã‚¿ãƒ¼ãƒ³  
                        3. **RMW**: ROEã§åç›Šæ€§é«˜/ä½ã«åˆ†é¡ â†’ é«˜åç›Šæ ªãƒªã‚¿ãƒ¼ãƒ³ - ä½åç›Šæ ªãƒªã‚¿ãƒ¼ãƒ³
                        4. **CMA**: æŠ•è³‡ç‡ã§ä¿å®ˆ/ç©æ¥µã«åˆ†é¡ â†’ ä¿å®ˆçš„ä¼æ¥­ãƒªã‚¿ãƒ¼ãƒ³ - ç©æ¥µä¼æ¥­ãƒªã‚¿ãƒ¼ãƒ³
                        5. **Mom**: éå»12ãƒ¶æœˆãƒªã‚¿ãƒ¼ãƒ³ã§åˆ†é¡ â†’ ä¸Šæ˜‡æ ªãƒªã‚¿ãƒ¼ãƒ³ - ä¸‹è½æ ªãƒªã‚¿ãƒ¼ãƒ³
                        
                        ---
                        
                        ## âš ï¸ **ä½¿ç”¨ä¸Šã®é‡è¦ãªç•™æ„ç‚¹**
                        
                        ### ğŸŒ **åœ°åŸŸçš„åˆ¶ç´„**
                        - ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã¯ **ç±³å›½å¸‚å ´ãƒ™ãƒ¼ã‚¹** ã§è¨ˆç®—
                        - ã‚ãªãŸã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã« **æ—¥æœ¬æ ªãƒ»æ¬§å·æ ªãƒ»æ–°èˆˆå›½æ ª** ãŒå«ã¾ã‚Œã‚‹å ´åˆï¼š
                          - ãƒ™ãƒ¼ã‚¿å€¤ã¯ã€Œç±³å›½å¸‚å ´ã®ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã«å¯¾ã™ã‚‹æ„Ÿå¿œåº¦ã€ã¨ã—ã¦è§£é‡ˆ
                          - åœ°åŸŸå›ºæœ‰ã®ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼ˆä¾‹ï¼šæ—¥æœ¬æ ªã®ã€Œå“è³ªãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã€ï¼‰ã¯åæ˜ ã•ã‚Œãªã„
                          - **æ¨å¥¨**: åœ°åŸŸåˆ¥ã«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’åˆ†ã‘ã¦åˆ†æ
                        
                        ### ğŸ“… **æ™‚æœŸçš„åˆ¶ç´„**  
                        - ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®åŠ¹æœã¯ **æ™‚æœŸã«ã‚ˆã£ã¦å¤‰å‹•**
                        - éå»ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯å°†æ¥ã‚’ä¿è¨¼ã—ãªã„
                        - é‡‘èå±æ©Ÿæ™‚ãªã©ã¯é€šå¸¸ã¨ç•°ãªã‚‹ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼é–¢ä¿‚ã«ãªã‚‹å¯èƒ½æ€§
                        
                        ### ğŸ“Š **çµ±è¨ˆçš„åˆ¶ç´„**
                        - **æ±ºå®šä¿‚æ•°(RÂ²)ãŒä½ã„å ´åˆ**: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã§èª¬æ˜ã§ããªã„éƒ¨åˆ†ãŒå¤§ãã„
                        - **æœ‰æ„ã§ãªã„ãƒ™ãƒ¼ã‚¿**: ãã®ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã¯ä¸æ˜ç¢º
                        - **æ¨å¥¨**: è¤‡æ•°æœŸé–“ã§ã®åˆ†æã€ä»–ã®åˆ†ææ‰‹æ³•ã¨ã®ä½µç”¨
                        
                        ### ğŸ’¼ **æŠ•è³‡åˆ¤æ–­ã§ã®æ´»ç”¨æ³•**
                        - ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æã¯ **ã€Œç¾åœ¨ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç‰¹æ€§ã®æŠŠæ¡ã€** ãŒä¸»ç›®çš„
                        - æ„å›³ã—ãªã„ãƒªã‚¹ã‚¯ã®ç™ºè¦‹ï¼ˆä¾‹ï¼šæ€ã£ãŸä»¥ä¸Šã«å°å‹æ ªã«åã£ã¦ã„ã‚‹ï¼‰
                        - ãƒªãƒãƒ©ãƒ³ã‚¹ã®å‚è€ƒï¼ˆä¾‹ï¼šãƒãƒªãƒ¥ãƒ¼åé‡ã‚’æ˜¯æ­£ã—ãŸã„ï¼‰
                        - **æ³¨æ„**: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æã ã‘ã§æŠ•è³‡åˆ¤æ–­ã‚’ã—ãªã„ã“ã¨
                        
                        ---
                        
                        ## ğŸ¯ **å®Ÿè·µçš„ãªæ´»ç”¨ä¾‹**
                        
                        ### **Case 1: ãƒãƒ©ãƒ³ã‚¹å‹æŠ•è³‡å®¶**
                        - å…¨ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®ãƒ™ãƒ¼ã‚¿ãŒ -0.2 ï½ 0.2 ã®ç¯„å›²
                        - â†’ ç‰¹å®šã®ã‚¹ã‚¿ã‚¤ãƒ«ã«åã‚‰ãªã„ãƒãƒ©ãƒ³ã‚¹æŠ•è³‡
                        
                        ### **Case 2: ã‚°ãƒ­ãƒ¼ã‚¹æŠ•è³‡å®¶** 
                        - SMB > 0 (å°å‹æ ª)ã€HML < 0 (æˆé•·æ ª)ã€Mom > 0 (ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ )
                        - â†’ å°å‹æˆé•·æ ªã®ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ç‹™ã„
                        
                        ### **Case 3: ãƒãƒªãƒ¥ãƒ¼æŠ•è³‡å®¶**
                        - HML > 0 (å‰²å®‰æ ª)ã€RMW > 0 (é«˜åç›Š)ã€CMA > 0 (å …å®ŸçµŒå–¶)  
                        - â†’ å …å®Ÿãªå‰²å®‰æ ªæŠ•è³‡
                        
                        ğŸ’¡ **ã‚ãªãŸã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ã©ã®ã‚¿ã‚¤ãƒ—ã«è¿‘ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ**
                        """)
                        
                        st.info("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ã“ã®åˆ†æçµæœã‚’å‚è€ƒã«ã€æ„å›³ã—ãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«ãªã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼")
                with show_loading_spinner("Fama-French ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
                    try:
                        # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‹ã‚‰ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆé¸æŠã•ã‚ŒãŸæœŸé–“ã«å¿œã˜ã¦ï¼‰
                        factor_start_date = start_date.strftime('%Y-%m-%d')
                        factor_end_date = datetime.now().strftime('%Y-%m-%d')
                        
                        factor_data = data_adapter.get_fama_french_factors(
                            start_date=factor_start_date, 
                            end_date=factor_end_date
                        )
                        
                        if isinstance(factor_data, pd.DataFrame) and not factor_data.empty:
                            # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“æƒ…å ±ã‚’è¡¨ç¤º
                            actual_start = factor_data.index.min().strftime('%Y-%m-%d') if hasattr(factor_data.index, 'strftime') else str(factor_data.index.min())
                            actual_end = factor_data.index.max().strftime('%Y-%m-%d') if hasattr(factor_data.index, 'strftime') else str(factor_data.index.max())
                            
                            st.success(f"ğŸ¯ **Fama-French ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ä¸­ ({analysis_period}æœŸé–“)**\n\n"
                                     f"- ğŸ“Š é¸æŠæœŸé–“: {factor_start_date} ï½ {factor_end_date}\n"
                                     f"- ğŸ“ˆ å®Ÿéš›ãƒ‡ãƒ¼ã‚¿: {actual_start} ï½ {actual_end}\n"
                                     f"- ğŸ“… ãƒ‡ãƒ¼ã‚¿æ•°: {len(factor_data):,}å–¶æ¥­æ—¥åˆ†\n"
                                     f"- ğŸ” ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼: {', '.join(factor_data.columns)}")
                        
                        if factor_data is not None and not factor_data.empty:
                            # ãƒ­ãƒã‚¹ãƒˆãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—ã‚’å®Ÿè¡Œ
                            st.info(f"ğŸ”„ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—ä¸­... å¯¾è±¡éŠ˜æŸ„: {', '.join(tickers)}, æœŸé–“: {analysis_period}")
                            
                            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                            with st.expander("ğŸ” ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æãƒ‡ãƒ¼ã‚¿æƒ…å ±"):
                                st.write("**åˆ†æè¨­å®š:**")
                                st.write(f"- ãƒ‡ãƒ¼ã‚¿æœŸé–“: {analysis_period}")
                                st.write(f"- å¯¾è±¡éŠ˜æŸ„æ•°: {len(tickers)}")
                                st.write("**PnLãƒ‡ãƒ¼ã‚¿æ§‹é€ :**")
                                st.write(f"- Shape: {pnl_df.shape}")
                                st.write(f"- Columns: {pnl_df.columns.tolist()}")
                                st.write("**PnLãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:**")
                                st.dataframe(pnl_df[['ticker', 'shares', 'current_value_jpy']].head())
                            
                            # ãƒ­ãƒã‚¹ãƒˆãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
                            portfolio_returns = calculate_portfolio_returns_robust(pnl_df, period=analysis_period)
                            
                            # çµæœã®ç¢ºèª
                            if portfolio_returns.empty:
                                st.error("âŒ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                                st.info("ğŸ’¡ ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š")
                                st.write("- ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ãŒæ­£ã—ã„ã‹")
                                st.write("- é¸æŠã—ãŸãƒ‡ãƒ¼ã‚¿æœŸé–“ã«æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹")
                                st.write("- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãŒæ­£å¸¸ã‹")
                            else:
                                st.success(f"âœ… ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—å®Œäº†: {len(portfolio_returns)}æ—¥åˆ†")
                                with st.expander("ğŸ“Š ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³çµ±è¨ˆ"):
                                    st.write(f"**åŸºæœ¬çµ±è¨ˆ (æ—¥æ¬¡):**")
                                    st.write(f"- å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³: {portfolio_returns.mean():.6f} ({portfolio_returns.mean()*252:.3%} å¹´ç‡)")
                                    st.write(f"- ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {portfolio_returns.std():.6f} ({portfolio_returns.std()*np.sqrt(252):.3%} å¹´ç‡)")
                                    st.write(f"- æœ€å¤§: {portfolio_returns.max():.6f}")
                                    st.write(f"- æœ€å°: {portfolio_returns.min():.6f}")
                                    st.write(f"- ãƒ‡ãƒ¼ã‚¿æœŸé–“: {portfolio_returns.index[0].strftime('%Y-%m-%d')} ~ {portfolio_returns.index[-1].strftime('%Y-%m-%d')}")
                            
                            if not portfolio_returns.empty:
                                # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å›å¸°åˆ†æ
                                factor_results = perform_factor_regression(portfolio_returns, factor_data)
                                
                                if factor_results:
                                    col1, col2 = st.columns(2)
                                    
                                    with col1:
                                        # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ™ãƒ¼ã‚¿ã®ãƒãƒ£ãƒ¼ãƒˆ
                                        beta_chart = create_factor_beta_chart(factor_results)
                                        st.plotly_chart(beta_chart, use_container_width=True)
                                        
                                        # å›å¸°çµ±è¨ˆ
                                        st.subheader("ğŸ“ˆ å›å¸°çµ±è¨ˆ")
                                        alpha = factor_results.get('alpha', 0)
                                        alpha_pval = factor_results.get('alpha_pvalue', 1)
                                        r_squared = factor_results.get('r_squared', 0)
                                        
                                        col_a, col_b = st.columns(2)
                                        with col_a:
                                            alpha_significance = "æœ‰æ„" if alpha_pval < 0.05 else "éæœ‰æ„"
                                            st.metric(
                                                "ã‚¢ãƒ«ãƒ•ã‚¡ï¼ˆå¹´ç‡ï¼‰",
                                                f"{alpha * 252:.2%}",
                                                f"på€¤: {alpha_pval:.3f} ({alpha_significance})"
                                            )
                                        with col_b:
                                            st.metric("æ±ºå®šä¿‚æ•° (RÂ²)", f"{r_squared:.3f}", f"èª¬æ˜åŠ›: {r_squared*100:.1f}%")
                                    
                                    with col2:
                                        # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è§£é‡ˆ
                                        st.subheader("ğŸ” ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è§£é‡ˆ")
                                        betas = factor_results.get('betas', {})
                                        pvalues = factor_results.get('factor_pvalues', {})
                                        
                                        for factor, beta in betas.items():
                                            pval = pvalues.get(factor, 1.0)
                                            significance = ""
                                            if pval < 0.01:
                                                significance = "ğŸŸ¢ é«˜åº¦ã«æœ‰æ„"
                                            elif pval < 0.05:
                                                significance = "ğŸŸ¡ æœ‰æ„"
                                            elif pval < 0.1:
                                                significance = "ğŸŸ  ã‚„ã‚„æœ‰æ„"
                                            else:
                                                significance = "âšª éæœ‰æ„"
                                            
                                            interpretation = get_factor_interpretation(factor, beta)
                                            st.write(f"**{factor}**: {beta:.3f} ({significance})")
                                            st.write(f"ã€€â†’ {interpretation}")
                                            st.write("")
                                    
                                    # ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¿åˆ†æ
                                    with st.expander("ğŸ“ˆ ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¿åˆ†æï¼ˆæ™‚ç³»åˆ—ï¼‰"):
                                        rolling_betas = calculate_rolling_betas(portfolio_returns, factor_data)
                                        if not rolling_betas.empty:
                                            rolling_chart = create_rolling_beta_chart(rolling_betas, analysis_period)
                                            st.plotly_chart(rolling_chart, use_container_width=True)
                                            
                                            st.info("ğŸ’¡ ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¿ã¯ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®æ™‚é–“å¤‰åŒ–ã‚’ç¤ºã—ã¾ã™ï¼ˆ1ãƒ¶æœˆçª“ï¼‰ã€‚æ€¥æ¿€ãªå¤‰åŒ–ã¯æŠ•è³‡ã‚¹ã‚¿ã‚¤ãƒ«ã®å¤‰æ›´ã‚„ãƒªãƒãƒ©ãƒ³ã‚¹ã‚’ç¤ºå”†ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                                        else:
                                            st.warning("ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¿ã®è¨ˆç®—ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½1ãƒ¶æœˆåˆ†å¿…è¦ï¼‰")
                                    
                                    # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å¯„ä¸åº¦åˆ†æ
                                    with st.expander("ğŸ“Š ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å¯„ä¸åº¦åˆ†æ"):
                                        contributions = calculate_factor_contributions(factor_data, betas)
                                        if not contributions.empty:
                                            contribution_chart = create_factor_contribution_chart(contributions, analysis_period)
                                            st.plotly_chart(contribution_chart, use_container_width=True)
                                            
                                            # ç·å¯„ä¸åº¦ã‚µãƒãƒªãƒ¼
                                            total_contributions = contributions.sum()
                                            st.subheader("ğŸ“‹ ç´¯ç©å¯„ä¸åº¦ã‚µãƒãƒªãƒ¼")
                                            for factor, contrib in total_contributions.items():
                                                contrib_pct = contrib * 100
                                                if contrib_pct > 0:
                                                    st.write(f"âœ… **{factor}**: +{contrib_pct:.2f}% ï¼ˆãƒ—ãƒ©ã‚¹å¯„ä¸ï¼‰")
                                                else:
                                                    st.write(f"âŒ **{factor}**: {contrib_pct:.2f}% ï¼ˆãƒã‚¤ãƒŠã‚¹å¯„ä¸ï¼‰")
                                        else:
                                            st.warning("ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å¯„ä¸åº¦ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                                
                                else:
                                    st.warning("ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å›å¸°åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿æœŸé–“ã‚„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹æˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                            else:
                                st.warning("ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®å–å¾—çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        else:
                            st.warning("ğŸš« **Fama-French 5å¹´åˆ†ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“**\n\n"
                                     "è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :\n"
                                     "1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã®å•é¡Œ\n"
                                     "2. Kenneth Frenchã‚µã‚¤ãƒˆã®ä¸€æ™‚çš„ãªå•é¡Œ\n"
                                     "3. ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å•é¡Œ\n\n"
                                     "**å¯¾å‡¦æ–¹æ³•:**\n"
                                     "- ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„\n"
                                     "- ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„")
                            
                            if isinstance(factor_data, pd.DataFrame):
                                st.info(f"ğŸ“Š å–å¾—ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿: {len(factor_data)}è¡Œ (ç©ºã®DataFrame)")
                            else:
                                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚¨ãƒ©ãƒ¼: {type(factor_data)}")
                    
                    except Exception as e:
                        st.error(f"ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                        logger.error(f"ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
                
                # çµ±è¨ˆæƒ…å ±ã®è©³ç´°è¡¨ç¤º
                with st.expander(f"ğŸ“ˆ è©³ç´°çµ±è¨ˆï¼ˆ{scale_label}æ¬¡ãƒ™ãƒ¼ã‚¹ï¼‰"):
                    stats_col1, stats_col2 = st.columns(2)
                    
                    with stats_col1:
                        st.write(f"**ãƒªã‚¿ãƒ¼ãƒ³çµ±è¨ˆï¼ˆ{scale_label}æ¬¡ï¼‰:**")
                        
                        # æ™‚é–“è»¸ã«å¿œã˜ãŸçµ±è¨ˆè¡¨ç¤º
                        if time_scale == "æ—¥æ¬¡":
                            avg_return_scaled = portfolio_returns.mean()
                            max_return_scaled = portfolio_returns.max()
                            min_return_scaled = portfolio_returns.min()
                            st.write(f"å¹³å‡æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(avg_return_scaled * 100)}")
                            st.write(f"æœ€å¤§æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(max_return_scaled * 100)}")
                            st.write(f"æœ€å°æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(min_return_scaled * 100)}")
                            st.write(f"å¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆå‚è€ƒï¼‰: {format_percentage(avg_return_scaled * 252 * 100)}")
                        
                        elif time_scale == "æœˆæ¬¡":
                            avg_return_scaled = portfolio_returns.mean() * 20  # 20å–¶æ¥­æ—¥
                            max_return_scaled = portfolio_returns.max() * np.sqrt(20)
                            min_return_scaled = portfolio_returns.min() * np.sqrt(20)
                            st.write(f"å¹³å‡æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(avg_return_scaled * 100)}")
                            st.write(f"æƒ³å®šæœ€å¤§æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(max_return_scaled * 100)}")
                            st.write(f"æƒ³å®šæœ€å°æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(min_return_scaled * 100)}")
                            st.write(f"å¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆå‚è€ƒï¼‰: {format_percentage(avg_return_scaled * 12 * 100)}")
                        
                        elif time_scale == "å¹´æ¬¡":
                            avg_return_scaled = portfolio_returns.mean() * 252  # 252å–¶æ¥­æ—¥
                            max_return_scaled = portfolio_returns.max() * np.sqrt(252)
                            min_return_scaled = portfolio_returns.min() * np.sqrt(252)
                            st.write(f"å¹³å‡å¹´æ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(avg_return_scaled * 100)}")
                            st.write(f"æƒ³å®šæœ€å¤§å¹´æ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(max_return_scaled * 100)}")
                            st.write(f"æƒ³å®šæœ€å°å¹´æ¬¡ãƒªã‚¿ãƒ¼ãƒ³: {format_percentage(min_return_scaled * 100)}")
                    
                    with stats_col2:
                        st.write("**ãƒªã‚¹ã‚¯çµ±è¨ˆ:**")
                        skewness = portfolio_returns.skew()
                        kurtosis = portfolio_returns.kurtosis()
                        daily_vol = portfolio_returns.std()
                        scaled_vol = daily_vol * scale_factor
                        
                        st.write(f"æ­ªåº¦: {skewness:.3f}")
                        st.write(f"å°–åº¦: {kurtosis:.3f}")
                        st.write(f"{scale_label}æ¬¡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {format_percentage(scaled_vol * 100)}")
                        st.write(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {len(portfolio_returns)}å–¶æ¥­æ—¥")
                        st.write(f"æ¬ æãƒ‡ãƒ¼ã‚¿: {portfolio_returns.isna().sum()}æ—¥")
    
    except Exception as e:
        display_error_message(e, "ãƒªã‚¹ã‚¯åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")


def display_allocation_analysis(pnl_df: pd.DataFrame, tickers: List[str]):
    """é…åˆ†åˆ†æã®è¡¨ç¤º"""
    st.subheader("ğŸŒ é…åˆ†åˆ†æ")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸä¼æ¥­æƒ…å ±ã‚’å–å¾—
        data_adapter = st.session_state.get('data_adapter')
        if not data_adapter:
            st.error("ãƒ‡ãƒ¼ã‚¿ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
            return
        
        with show_loading_spinner("ä¼æ¥­æƒ…å ±ã‚’å‡¦ç†ä¸­..."):
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå®Œå…¨ãªä¼æ¥­æƒ…å ±ã‚’å–å¾—
            ticker_complete_info = data_adapter.get_multiple_ticker_complete_info(tickers)
            
            # é…åˆ†åˆ†æç”¨ã«åŸºæœ¬æƒ…å ±ã®ã¿ã‚’æŠ½å‡º
            ticker_info = {}
            for ticker, info in ticker_complete_info.items():
                ticker_info[ticker] = {
                    'country': info.get('country'),
                    'sector': info.get('sector')
                }
            
            # å–å¾—çŠ¶æ³ã®ç¢ºèª
            country_success = sum(1 for info in ticker_info.values() if info.get('country'))
            sector_success = sum(1 for info in ticker_info.values() if info.get('sector'))
            
            st.info(f"ä¼æ¥­æƒ…å ±ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ˆã‚Šï¼‰: å›½æƒ…å ± {country_success}/{len(tickers)}éŠ˜æŸ„, ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ± {sector_success}/{len(tickers)}éŠ˜æŸ„")
        
        # åˆ†æã‚¿ã‚¤ãƒ—ã®é¸æŠ
        analysis_type = st.radio(
            "åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠ:",
            options=["åœ°åŸŸåˆ¥", "ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥"],
            horizontal=True,
            key="allocation_analysis_type"
        )
        
        if analysis_type == "åœ°åŸŸåˆ¥":
            # åœ°åŸŸåˆ¥é…åˆ†åˆ†æ
            ticker_countries = {ticker: info['country'] for ticker, info in ticker_info.items()}
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
            with st.expander("ğŸ” æœ¬ç¤¾æ‰€åœ¨å›½æƒ…å ±ã®è©³ç´°"):
                st.write("**å–å¾—ã•ã‚ŒãŸæœ¬ç¤¾æ‰€åœ¨å›½æƒ…å ±:**")
                for ticker, country in ticker_countries.items():
                    status = "âœ…" if country else "âŒ"
                    country_display = country if country else "å–å¾—å¤±æ•—"
                    st.write(f"{status} **{ticker}**: {country_display}")
            
            # åœ°åŸŸåˆ¥é…åˆ†ã‚’è¨ˆç®—
            allocation_df = calculate_sector_allocation_by_region(pnl_df, ticker_countries)
            category_label = "åœ°åŸŸ"
            
        else:  # ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
            with st.expander("ğŸ” ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ã®è©³ç´°"):
                st.write("**å–å¾—ã•ã‚ŒãŸã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±:**")
                for ticker, info in ticker_info.items():
                    sector = info.get('sector')
                    status = "âœ…" if sector else "âŒ"
                    sector_display = sector if sector else "å–å¾—å¤±æ•—"
                    st.write(f"{status} **{ticker}**: {sector_display}")
            
            # ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é…åˆ†ã‚’è¨ˆç®—
            allocation_df = calculate_sector_allocation(pnl_df, ticker_info)
            category_label = "ã‚»ã‚¯ã‚¿ãƒ¼"
        
        if not allocation_df.empty:
            # é…åˆ†ãƒãƒ£ãƒ¼ãƒˆ
            try:
                allocation_chart = create_sector_allocation_chart(allocation_df)
                allocation_chart.update_layout(title=f'{category_label}åˆ¥é…åˆ†')
                st.plotly_chart(allocation_chart, use_container_width=True)
            except Exception as chart_error:
                st.error(f"ãƒãƒ£ãƒ¼ãƒˆä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(chart_error)}")
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                st.write("**é…åˆ†ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹:**")
                st.dataframe(allocation_df)
            
            # é…åˆ†ãƒ†ãƒ¼ãƒ–ãƒ«
            st.subheader(f"ğŸ“‹ {category_label}åˆ¥é…åˆ†è©³ç´°")
            display_df = allocation_df.copy()
            
            # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›´
            column_mapping = {
                'country': category_label,
                'sector': category_label,
                'current_value_jpy': 'ç¾åœ¨ä¾¡å€¤ï¼ˆå††ï¼‰',
                'cost_basis_jpy': 'å–å¾—åŸä¾¡ï¼ˆå††ï¼‰',
                'pnl_amount': 'æç›Šé‡‘é¡ï¼ˆå††ï¼‰',
                'position_count': 'éŠ˜æŸ„æ•°',
                'allocation_percentage': 'é…åˆ†æ¯”ç‡ï¼ˆ%ï¼‰',
                'pnl_percentage': 'æç›Šç‡ï¼ˆ%ï¼‰'
            }
            display_df = display_df.rename(columns=column_mapping)
            
            # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            display_df['ç¾åœ¨ä¾¡å€¤ï¼ˆå††ï¼‰'] = display_df['ç¾åœ¨ä¾¡å€¤ï¼ˆå††ï¼‰'].apply(lambda x: format_currency(x))
            display_df['å–å¾—åŸä¾¡ï¼ˆå††ï¼‰'] = display_df['å–å¾—åŸä¾¡ï¼ˆå††ï¼‰'].apply(lambda x: format_currency(x))
            display_df['æç›Šé‡‘é¡ï¼ˆå††ï¼‰'] = display_df['æç›Šé‡‘é¡ï¼ˆå††ï¼‰'].apply(lambda x: format_currency(x))
            display_df['é…åˆ†æ¯”ç‡ï¼ˆ%ï¼‰'] = display_df['é…åˆ†æ¯”ç‡ï¼ˆ%ï¼‰'].apply(lambda x: format_percentage(x))
            display_df['æç›Šç‡ï¼ˆ%ï¼‰'] = display_df['æç›Šç‡ï¼ˆ%ï¼‰'].apply(lambda x: format_percentage(x))
            
            st.dataframe(display_df, use_container_width=True)
            
            # ã‚µãƒãƒªãƒ¼æƒ…å ±
            st.subheader(f"ğŸ“Š {category_label}åˆ¥ã‚µãƒãƒªãƒ¼")
            col1, col2, col3 = st.columns(3)
            
            category_col = 'country' if analysis_type == "åœ°åŸŸåˆ¥" else 'sector'
            
            with col1:
                top_category = allocation_df.loc[allocation_df['allocation_percentage'].idxmax(), category_col]
                top_allocation = allocation_df['allocation_percentage'].max()
                st.metric(f"æœ€å¤§é…åˆ†{category_label}", f"{top_category}", f"{top_allocation:.1f}%")
            
            with col2:
                best_category = allocation_df.loc[allocation_df['pnl_percentage'].idxmax(), category_col]
                best_performance = allocation_df['pnl_percentage'].max()
                st.metric(f"æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹{category_label}", f"{best_category}", f"{best_performance:+.1f}%")
            
            with col3:
                total_categories = len(allocation_df)
                profitable_categories = len(allocation_df[allocation_df['pnl_percentage'] > 0])
                st.metric("åˆ†æ•£çŠ¶æ³", f"{total_categories}{category_label}", f"åˆ©ç›Š{category_label}: {profitable_categories}")
        else:
            st.warning(f"{category_label}åˆ¥é…åˆ†ãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä¼æ¥­æƒ…å ±ã®å–å¾—çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            st.write("**ãƒ‡ãƒãƒƒã‚°æƒ…å ±:**")
            if analysis_type == "ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥":
                sector_count = sum(1 for info in ticker_info.values() if info and info.get('sector'))
                st.write(f"ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±å–å¾—æˆåŠŸ: {sector_count}/{len(tickers)}éŠ˜æŸ„")
            else:
                country_count = sum(1 for info in ticker_info.values() if info and info.get('country'))
                st.write(f"å›½æƒ…å ±å–å¾—æˆåŠŸ: {country_count}/{len(tickers)}éŠ˜æŸ„")
    
    except Exception as e:
        display_error_message(e, "é…åˆ†åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")


def display_valuation_analysis(pnl_df: pd.DataFrame, tickers: List[str]):
    """ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã®è¡¨ç¤º"""
    st.subheader("ğŸ’° ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        data_adapter = st.session_state.get('data_adapter')
        if not data_adapter:
            st.error("ãƒ‡ãƒ¼ã‚¿ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
            return
        
        with show_loading_spinner("ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å‡¦ç†ä¸­..."):
            try:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå®Œå…¨ãªä¼æ¥­æƒ…å ±ã‚’å–å¾—
                ticker_complete_info = data_adapter.get_multiple_ticker_complete_info(tickers)
                
                # ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœã®æ¤œè¨¼
                if not ticker_complete_info:
                    st.error("ä¼æ¥­æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
                    return
                
                # æˆåŠŸã—ãŸéŠ˜æŸ„æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                successful_tickers = [ticker for ticker, info in ticker_complete_info.items() 
                                    if info and (info.get('country') or info.get('sector'))]
                
                if len(successful_tickers) == 0:
                    st.error("ã™ã¹ã¦ã®éŠ˜æŸ„ã§ä¼æ¥­æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                    return
                elif len(successful_tickers) < len(tickers):
                    failed_tickers = [ticker for ticker in tickers if ticker not in successful_tickers]
                    st.warning(f"ä¸€éƒ¨ã®éŠ˜æŸ„ã§æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(failed_tickers)}")
                    st.info(f"åˆ©ç”¨å¯èƒ½: {len(successful_tickers)}/{len(tickers)}éŠ˜æŸ„")
                else:
                    st.success(f"ã™ã¹ã¦ã®éŠ˜æŸ„ã®ä¼æ¥­æƒ…å ±ã‚’åˆ©ç”¨ã§ãã¾ã™: {len(successful_tickers)}éŠ˜æŸ„")
                    
            except Exception as e:
                st.error(f"ä¼æ¥­æƒ…å ±å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return
        
        # ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’è¨ˆç®—
        valuation_stats_df = calculate_portfolio_valuation_metrics(pnl_df, ticker_complete_info)
        
        if not valuation_stats_df.empty:
            st.subheader("ğŸ“Š ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³çµ±è¨ˆ")
            
            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒã®èª¬æ˜
            st.info("ğŸ’¡ **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒ**: å·¦å´ã®4åˆ—ï¼ˆMSCI ACWIã€NASDAQ-100ã€S&P 500ã€TOPIXï¼‰ã¯ä¸»è¦å¸‚å ´æŒ‡æ•°ã®ETFæŒ‡æ¨™å€¤ã§ã™ã€‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®åŠ é‡å¹³å‡ã¨æ¯”è¼ƒã§ãã¾ã™ã€‚")
            
            # çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡¨ç¤º
            display_stats_df = valuation_stats_df.copy()
            
            # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé–¢æ•°
            def format_valuation_value(value, metric_name):
                if value is None or pd.isna(value):
                    return "-"
                try:
                    if metric_name in ['ROE', 'ROA', 'å–¶æ¥­åˆ©ç›Šç‡', 'ç´”åˆ©ç›Šç‡']:
                        # è²¡å‹™æŒ‡æ¨™ã¯å°æ•°å½¢å¼ãªã®ã§100å€ã—ã¦ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
                        return f"{value * 100:.2f}%"
                    elif metric_name in ['é…å½“åˆ©å›ã‚Š']:
                        # é…å½“åˆ©å›ã‚Šã¯æ—¢ã«ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå€¤ã®å ´åˆãŒå¤šã„
                        return f"{value:.2f}%"
                    elif metric_name in ['æ™‚ä¾¡ç·é¡ï¼ˆå††ï¼‰']:
                        if value >= 1e12:
                            return f"{value/1e12:.2f}å…†å††"
                        elif value >= 1e9:
                            return f"{value/1e9:.2f}å„„å††"
                        elif value >= 1e6:
                            return f"{value/1e6:.2f}ç™¾ä¸‡å††"
                        else:
                            return f"{value:,.0f}å††"
                    else:
                        return f"{value:.2f}"
                except:
                    return "-"
            
            # ETFãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åˆ—ã‚’ç‰¹å®š
            etf_columns = ['MSCI ACWI', 'NASDAQ-100', 'S&P 500', 'TOPIX (Japan)']
            
            # æ•°å€¤åˆ—ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªçµ±è¨ˆã¨ETFãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åˆ—ã®ä¸¡æ–¹ï¼‰
            numeric_cols = ['åŠ é‡å¹³å‡', 'ä¸­å¤®å€¤', '25%ã‚¿ã‚¤ãƒ«', '75%ã‚¿ã‚¤ãƒ«', 'æœ€å°å€¤', 'æœ€å¤§å€¤'] + etf_columns
            for col in numeric_cols:
                if col in display_stats_df.columns:
                    display_stats_df[col] = display_stats_df.apply(
                        lambda row: format_valuation_value(row[col], row['æŒ‡æ¨™']), axis=1
                    )
            
            st.dataframe(display_stats_df, use_container_width=True)
            
            # ã‚µãƒãƒªãƒ¼æƒ…å ±
            st.subheader("ğŸ“ˆ ä¸»è¦æŒ‡æ¨™ã‚µãƒãƒªãƒ¼")
            
            # é‡è¦ãªæŒ‡æ¨™ã‚’æŠœãå‡ºã—ã¦è¡¨ç¤º
            key_metrics = ['äºˆæƒ³PER', 'PBR', 'ROE', 'é…å½“åˆ©å›ã‚Š']
            
            cols = st.columns(len(key_metrics))
            for i, metric in enumerate(key_metrics):
                metric_row = valuation_stats_df[valuation_stats_df['æŒ‡æ¨™'] == metric]
                if not metric_row.empty:
                    weighted_avg = metric_row.iloc[0]['åŠ é‡å¹³å‡']
                    valid_count = metric_row.iloc[0]['æœ‰åŠ¹éŠ˜æŸ„æ•°']
                    
                    with cols[i]:
                        if weighted_avg is not None and not pd.isna(weighted_avg):
                            if metric == 'ROE':
                                # ROEã¯å°æ•°å½¢å¼ãªã®ã§100å€ã—ã¦ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
                                value_display = f"{weighted_avg * 100:.2f}%"
                            elif metric == 'é…å½“åˆ©å›ã‚Š':
                                # é…å½“åˆ©å›ã‚Šã¯æ—¢ã«ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå€¤
                                value_display = f"{weighted_avg:.2f}%"
                            else:
                                value_display = f"{weighted_avg:.2f}"
                            st.metric(
                                label=f"{metric}ï¼ˆåŠ é‡å¹³å‡ï¼‰",
                                value=value_display,
                                delta=f"æœ‰åŠ¹éŠ˜æŸ„: {valid_count}/{len(tickers)}"
                            )
                        else:
                            st.metric(
                                label=f"{metric}ï¼ˆåŠ é‡å¹³å‡ï¼‰",
                                value="ãƒ‡ãƒ¼ã‚¿ãªã—",
                                delta=f"æœ‰åŠ¹éŠ˜æŸ„: 0/{len(tickers)}"
                            )
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—çŠ¶æ³ã¨è¨ºæ–­æƒ…å ±
            with st.expander("ğŸ” ãƒ‡ãƒ¼ã‚¿å–å¾—çŠ¶æ³ã®è©³ç´°"):
                st.write("**ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—çµ±è¨ˆ:**")
                
                # åŸºæœ¬æƒ…å ±ã®å–å¾—çŠ¶æ³
                country_success = sum(1 for info in ticker_complete_info.values() if info and info.get('country'))
                sector_success = sum(1 for info in ticker_complete_info.values() if info and info.get('sector'))
                
                st.write(f"- æœ¬ç¤¾æ‰€åœ¨å›½: {country_success}/{len(tickers)}éŠ˜æŸ„ ({country_success/len(tickers)*100:.1f}%)")
                st.write(f"- ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±: {sector_success}/{len(tickers)}éŠ˜æŸ„ ({sector_success/len(tickers)*100:.1f}%)")
                
                st.write("**ğŸ’° ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ¨™ã®å–å¾—çŠ¶æ³:**")
                for _, row in valuation_stats_df.iterrows():
                    metric_name = row['æŒ‡æ¨™']
                    valid_count = row['æœ‰åŠ¹éŠ˜æŸ„æ•°']
                    success_rate = (valid_count / len(tickers)) * 100
                    
                    if success_rate >= 80:
                        status = "ğŸŸ¢"
                    elif success_rate >= 50:
                        status = "ğŸŸ¡" 
                    else:
                        status = "ğŸ”´"
                    
                    st.write(f"{status} **{metric_name}**: {valid_count}/{len(tickers)}éŠ˜æŸ„ ({success_rate:.1f}%)")
                
                # è¨ºæ–­ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
                st.write("**ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:**")
                low_success_metrics = [row['æŒ‡æ¨™'] for _, row in valuation_stats_df.iterrows() 
                                     if (row['æœ‰åŠ¹éŠ˜æŸ„æ•°'] / len(tickers)) < 0.5]
                
                if low_success_metrics:
                    st.warning(f"ä»¥ä¸‹ã®æŒ‡æ¨™ã®å–å¾—ç‡ãŒä½ã„ã§ã™: {', '.join(low_success_metrics)}")
                    st.write("**æ”¹å–„ææ¡ˆ:**")
                    st.write("- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                    st.write("- ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„") 
                    st.write("- ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ï¼ˆAPIåˆ¶é™ã®å¯èƒ½æ€§ï¼‰")
                    st.write("- ETFã‚„å€‹åˆ¥æ ªå¼ã§å–å¾—å¯èƒ½ãªæŒ‡æ¨™ãŒç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™")
                else:
                    st.success("ã™ã¹ã¦ã®æŒ‡æ¨™ãŒè‰¯å¥½ã«å–å¾—ã•ã‚Œã¦ã„ã¾ã™ï¼")
        else:
            st.warning("ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³çµ±è¨ˆã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä¼æ¥­æƒ…å ±ã®å–å¾—çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            st.write("**ãƒ‡ãƒãƒƒã‚°æƒ…å ±:**")
            valuation_keys = ['forwardPE', 'priceToBook', 'priceToSalesTrailing12Months', 
                            'enterpriseToEbitda', 'pegRatio', 'marketCap', 'beta', 'dividendYield',
                            'returnOnEquity', 'returnOnAssets', 'operatingMargins', 'profitMargins']
            
            for key in valuation_keys:
                count = sum(1 for info in ticker_complete_info.values() 
                          if info and info.get(key) is not None)
                st.write(f"{key}: {count}/{len(tickers)}éŠ˜æŸ„")
    
    except Exception as e:
        display_error_message(e, "ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")


def display_detailed_data(pnl_df: pd.DataFrame, original_df: pd.DataFrame, tickers: List[str]):
    """è©³ç´°ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º"""
    st.subheader("ğŸ” è©³ç´°ãƒ‡ãƒ¼ã‚¿")
    
    # æç›Šè©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
    st.subheader("ğŸ’° æç›Šè©³ç´°")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸä¼æ¥­æƒ…å ±ã‚’å–å¾—
        data_adapter = st.session_state.get('data_adapter')
        if not data_adapter:
            st.error("ãƒ‡ãƒ¼ã‚¿ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
            return
        
        with show_loading_spinner("è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå®Œå…¨ãªä¼æ¥­æƒ…å ±ã‚’å–å¾—
            ticker_complete_info = data_adapter.get_multiple_ticker_complete_info(tickers)
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœã®æ¤œè¨¼
            if not ticker_complete_info:
                st.error("ä¼æ¥­æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
                return
            
            # æˆåŠŸã—ãŸéŠ˜æŸ„æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            successful_count = sum(1 for info in ticker_complete_info.values() 
                                 if info and (info.get('country') or info.get('sector')))
            
            if successful_count == 0:
                st.error("ã™ã¹ã¦ã®éŠ˜æŸ„ã§ä¼æ¥­æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                return
            elif successful_count < len(tickers):
                st.info(f"ä¼æ¥­æƒ…å ±ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ˆã‚Šï¼‰: {successful_count}/{len(tickers)}éŠ˜æŸ„ã§åˆ©ç”¨å¯èƒ½")
            else:
                st.success(f"ä¼æ¥­æƒ…å ±ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ˆã‚Šï¼‰: {successful_count}/{len(tickers)}éŠ˜æŸ„ã§åˆ©ç”¨å¯èƒ½")
        
        # ä¼æ¥­åã‚’å–å¾—
        if 'company_names_cache' not in st.session_state:
            from modules.price_fetcher import cached_get_company_names
            with show_loading_spinner("ä¼æ¥­åã‚’å–å¾—ä¸­..."):
                st.session_state.company_names_cache = cached_get_company_names(tuple(tickers))
        
        company_names = st.session_state.company_names_cache
        
        # è¡¨ç¤ºç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        display_pnl_df = pnl_df.copy()
        
        # æœ¬ç¤¾æ‰€åœ¨å›½ã€åœ°åŸŸã€ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’è¿½åŠ 
        from modules.country_fetcher import classify_region_by_country
        
        def get_company_info(ticker):
            info = ticker_complete_info.get(ticker, {})
            if not info:
                info = {}
            
            country = info.get('country')
            sector = info.get('sector')
            region = classify_region_by_country(country)
            
            # ã‚»ã‚¯ã‚¿ãƒ¼ã®å‡¦ç†ï¼šå–å¾—å¤±æ•—æ™‚ã¯ã€Œãã®ä»–ã€ã¨ã™ã‚‹
            if not sector or (isinstance(sector, str) and sector.strip() == ""):
                if '.T' in str(ticker) or '.JP' in str(ticker):
                    sector_display = "ãã®ä»–ï¼ˆæ—¥æœ¬ï¼‰"
                else:
                    sector_display = "ãã®ä»–"
            else:
                sector_display = sector.strip()
            
            # ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ¨™ã‚’å–å¾—
            def safe_format_value(value, format_type='number', metric_key=None):
                if value is None or pd.isna(value):
                    return ""
                
                # å–¶æ¥­åˆ©ç›Šç‡ãƒ»ç´”åˆ©ç›Šç‡ã®å¤–ã‚Œå€¤ãƒã‚§ãƒƒã‚¯
                if metric_key in ['operatingMargins', 'profitMargins'] and value is not None:
                    if value < -1.0 or value > 1.0:
                        return ""  # å¤–ã‚Œå€¤ã¯ãƒ–ãƒ©ãƒ³ã‚¯è¡¨ç¤º
                
                try:
                    if format_type == 'percentage':
                        # Yahoo Financeã®è²¡å‹™æŒ‡æ¨™ã¯æ—¢ã«å°æ•°å½¢å¼ï¼ˆ0.10 = 10%ï¼‰ãªã®ã§100å€ã—ã¦ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
                        return f"{value * 100:.2f}%"
                    elif format_type == 'dividend_percentage':
                        # é…å½“åˆ©å›ã‚Šã¯æ—¢ã«ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå€¤ã¨ã—ã¦æä¾›ã•ã‚Œã‚‹å ´åˆãŒå¤šã„
                        return f"{value:.2f}%"
                    elif format_type == 'large_number':
                        # æ™‚ä¾¡ç·é¡ãªã©ã®å¤§ããªæ•°å€¤
                        if value >= 1e12:
                            return f"{value/1e12:.2f}T"
                        elif value >= 1e9:
                            return f"{value/1e9:.2f}B"
                        elif value >= 1e6:
                            return f"{value/1e6:.2f}M"
                        else:
                            return f"{value:,.0f}"
                    else:
                        return f"{value:.2f}"
                except:
                    return ""
            
            valuation_data = {
                'forwardPE': safe_format_value(info.get('forwardPE')),
                'priceToBook': safe_format_value(info.get('priceToBook')),
                'priceToSalesTrailing12Months': safe_format_value(info.get('priceToSalesTrailing12Months')),
                'enterpriseToEbitda': safe_format_value(info.get('enterpriseToEbitda')),
                'pegRatio': safe_format_value(info.get('pegRatio')),
                'marketCap': safe_format_value(info.get('marketCap'), 'large_number'),
                'beta': safe_format_value(info.get('beta')),
                'dividendYield': safe_format_value(info.get('dividendYield'), 'dividend_percentage'),
                'returnOnEquity': safe_format_value(info.get('returnOnEquity'), 'percentage'),
                'returnOnAssets': safe_format_value(info.get('returnOnAssets'), 'percentage'),
                'operatingMargins': safe_format_value(info.get('operatingMargins'), 'percentage', 'operatingMargins'),
                'profitMargins': safe_format_value(info.get('profitMargins'), 'percentage', 'profitMargins')
            }
            
            return (
                country if country else "å–å¾—å¤±æ•—",
                region,
                sector_display,
                valuation_data
            )
        
        # ä¼æ¥­æƒ…å ±ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
        company_data = [get_company_info(ticker) for ticker in display_pnl_df['ticker']]
        display_pnl_df['ä¼æ¥­å'] = [company_names.get(ticker, ticker) for ticker in display_pnl_df['ticker']]
        display_pnl_df['æœ¬ç¤¾æ‰€åœ¨å›½'] = [data[0] for data in company_data]
        display_pnl_df['åœ°åŸŸ'] = [data[1] for data in company_data]
        display_pnl_df['ã‚»ã‚¯ã‚¿ãƒ¼'] = [data[2] for data in company_data]
        
        # ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ¨™ã‚’è¿½åŠ 
        display_pnl_df['äºˆæƒ³PER'] = [data[3]['forwardPE'] for data in company_data]
        display_pnl_df['PBR'] = [data[3]['priceToBook'] for data in company_data]
        display_pnl_df['PSR'] = [data[3]['priceToSalesTrailing12Months'] for data in company_data]
        display_pnl_df['EV/EBITDA'] = [data[3]['enterpriseToEbitda'] for data in company_data]
        display_pnl_df['PEGãƒ¬ã‚·ã‚ª'] = [data[3]['pegRatio'] for data in company_data]
        display_pnl_df['æ™‚ä¾¡ç·é¡'] = [data[3]['marketCap'] for data in company_data]
        display_pnl_df['ãƒ™ãƒ¼ã‚¿'] = [data[3]['beta'] for data in company_data]
        display_pnl_df['é…å½“åˆ©å›ã‚Š'] = [data[3]['dividendYield'] for data in company_data]
        # æ–°ã—ã„è²¡å‹™æŒ‡æ¨™ã‚’è¿½åŠ 
        display_pnl_df['ROE'] = [data[3]['returnOnEquity'] for data in company_data]
        display_pnl_df['ROA'] = [data[3]['returnOnAssets'] for data in company_data]
        display_pnl_df['å–¶æ¥­åˆ©ç›Šç‡'] = [data[3]['operatingMargins'] for data in company_data]
        display_pnl_df['ç´”åˆ©ç›Šç‡'] = [data[3]['profitMargins'] for data in company_data]
        
        # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        numeric_columns = ['avg_cost_jpy', 'current_price_jpy', 'current_value_jpy', 
                          'cost_basis_jpy', 'pnl_amount']
        
        for col in numeric_columns:
            if col in display_pnl_df.columns:
                display_pnl_df[col] = display_pnl_df[col].apply(lambda x: format_currency(x))
        
        if 'pnl_percentage' in display_pnl_df.columns:
            display_pnl_df['pnl_percentage'] = display_pnl_df['pnl_percentage'].apply(
                lambda x: format_percentage(x)
            )
        
        # ã‚«ãƒ©ãƒ é †åºã‚’èª¿æ•´ï¼ˆåŸºæœ¬æƒ…å ±ã€æç›Šæƒ…å ±ã€ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ¨™ã®é †ï¼‰
        basic_columns = ['ticker', 'ä¼æ¥­å', 'æœ¬ç¤¾æ‰€åœ¨å›½', 'åœ°åŸŸ', 'ã‚»ã‚¯ã‚¿ãƒ¼']
        pnl_columns = ['shares', 'avg_cost_jpy', 'current_price_jpy', 'current_value_jpy', 
                      'cost_basis_jpy', 'pnl_amount', 'pnl_percentage']
        valuation_columns = ['äºˆæƒ³PER', 'PBR', 'PSR', 'EV/EBITDA', 'PEGãƒ¬ã‚·ã‚ª', 
                           'æ™‚ä¾¡ç·é¡', 'ãƒ™ãƒ¼ã‚¿', 'é…å½“åˆ©å›ã‚Š', 'ROE', 'ROA', 'å–¶æ¥­åˆ©ç›Šç‡', 'ç´”åˆ©ç›Šç‡']
        
        # å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ã‚’å«ã‚ã‚‹
        columns_order = []
        for col_list in [basic_columns, pnl_columns, valuation_columns]:
            columns_order.extend([col for col in col_list if col in display_pnl_df.columns])
        
        # æ®‹ã‚Šã®ã‚«ãƒ©ãƒ ã‚‚è¿½åŠ 
        other_columns = [col for col in display_pnl_df.columns if col not in columns_order]
        display_pnl_df = display_pnl_df[columns_order + other_columns]
        
        st.dataframe(display_pnl_df, use_container_width=True)
        
    except Exception as e:
        display_error_message(e, "è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®è¡¨ç¤ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        display_pnl_df = pnl_df.copy()
        numeric_columns = ['avg_cost_jpy', 'current_price_jpy', 'current_value_jpy', 
                          'cost_basis_jpy', 'pnl_amount']
        
        for col in numeric_columns:
            if col in display_pnl_df.columns:
                display_pnl_df[col] = display_pnl_df[col].apply(lambda x: format_currency(x))
        
        if 'pnl_percentage' in display_pnl_df.columns:
            display_pnl_df['pnl_percentage'] = display_pnl_df['pnl_percentage'].apply(
                lambda x: format_percentage(x)
            )
        
        st.dataframe(display_pnl_df, use_container_width=True)
    
    # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿
    with st.expander("ğŸ“„ ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿"):
        st.dataframe(original_df, use_container_width=True)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    col1, col2 = st.columns(2)
    
    with col1:
        pnl_csv = pnl_df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ æç›Šãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=pnl_csv,
            file_name="portfolio_pnl.csv",
            mime="text/csv"
        )
    
    with col2:
        original_csv = original_df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=original_csv,
            file_name="portfolio_original.csv",
            mime="text/csv"
        )


def display_stock_charts(tickers: List[str]):
    """æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆï¼ˆGeminiãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æä»˜ãï¼‰ã®è¡¨ç¤º"""
    st.subheader("ğŸ“Š æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆ")
    
    if not tickers:
        st.warning("è¡¨ç¤ºã™ã‚‹éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ãƒãƒ£ãƒ¼ãƒˆè¨­å®šã‚’ç®¡ç†
    if 'chart_ticker' not in st.session_state:
        st.session_state.chart_ticker = tickers[0] if tickers else ""
    if 'chart_from_date' not in st.session_state:
        st.session_state.chart_from_date = datetime.now() - timedelta(days=30)
    if 'chart_to_date' not in st.session_state:
        st.session_state.chart_to_date = datetime.now()
    if 'chart_model' not in st.session_state:
        st.session_state.chart_model = "gemini-1.5-pro"
    
    # 5å¹´å‰ã®æ—¥ä»˜åˆ¶é™
    max_past_date = datetime.now() - timedelta(days=5*365)
    
    st.markdown("### âš™ï¸ è¨­å®š")
    
    # éŠ˜æŸ„é¸æŠã¨æœŸé–“è¨­å®š
    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
    
    with col1:
        selected_ticker = st.selectbox(
            "è¡¨ç¤ºã™ã‚‹éŠ˜æŸ„ã‚’é¸æŠ",
            options=tickers,
            index=tickers.index(st.session_state.chart_ticker) if st.session_state.chart_ticker in tickers else 0,
            help="ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„",
            key="chart_ticker_selector"
        )
        st.session_state.chart_ticker = selected_ticker
    
    with col2:
        from_date = st.date_input(
            "é–‹å§‹æ—¥",
            value=st.session_state.chart_from_date.date(),
            min_value=max_past_date.date(),
            max_value=datetime.now().date(),
            help="ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºé–‹å§‹æ—¥ï¼ˆæœ€å¤§éå»5å¹´ã¾ã§ï¼‰",
            key="chart_from_date_input"
        )
        # æ—¥ä»˜åˆ¶é™ãƒã‚§ãƒƒã‚¯
        from_date_dt = datetime.combine(from_date, datetime.min.time())
        if from_date_dt < max_past_date:
            st.error(f"âš ï¸ é–‹å§‹æ—¥ã¯éå»5å¹´é–“ï¼ˆ{max_past_date.strftime('%Y-%m-%d')}ï¼‰ä»¥é™ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            from_date_dt = max_past_date
            st.info(f"é–‹å§‹æ—¥ã‚’ {max_past_date.strftime('%Y-%m-%d')} ã«è¨­å®šã—ã¾ã—ãŸã€‚")
        st.session_state.chart_from_date = from_date_dt
    
    with col3:
        to_date = st.date_input(
            "çµ‚äº†æ—¥",
            value=st.session_state.chart_to_date.date(),
            min_value=from_date,
            max_value=datetime.now().date(),
            help="ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºçµ‚äº†æ—¥",
            key="chart_to_date_input"
        )
        to_date_dt = datetime.combine(to_date, datetime.min.time())
        
        # æœŸé–“å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if to_date_dt <= from_date_dt:
            st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã®æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            return
        
        # æœŸé–“ãŒé•·ã™ããªã„ã‹ãƒã‚§ãƒƒã‚¯
        days_diff = (to_date_dt - from_date_dt).days
        if days_diff > 5*365:
            st.error("âš ï¸ é¸æŠæœŸé–“ãŒ5å¹´ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚æœŸé–“ã‚’çŸ­ç¸®ã—ã¦ãã ã•ã„ã€‚")
            return
            
        st.session_state.chart_to_date = to_date_dt
    
    with col4:
        model_options = ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-1.0-pro"]
        selected_model = st.selectbox(
            "Geminiãƒ¢ãƒ‡ãƒ«",
            options=model_options,
            index=model_options.index(st.session_state.chart_model) if st.session_state.chart_model in model_options else 0,
            help="ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æã«ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            key="chart_model_selector"
        )
        st.session_state.chart_model = selected_model
    
    if selected_ticker and from_date_dt and to_date_dt:
        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸéå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            data_adapter = st.session_state.get('data_adapter')
            if not data_adapter:
                st.error("ãƒ‡ãƒ¼ã‚¿ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
                return
            
            with show_loading_spinner(f"{selected_ticker}ã®ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
                # 5å¹´é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                full_data = data_adapter.get_historical_data(selected_ticker, period="5y")
                
                if not full_data.empty:
                    # æŒ‡å®šæœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    chart_data = full_data[
                        (full_data.index >= from_date_dt) & 
                        (full_data.index <= to_date_dt)
                    ]
                else:
                    chart_data = pd.DataFrame()
                
                if not chart_data.empty:
                    # çµ‚å€¤ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ
                    period_str = f"{from_date_dt.strftime('%Y-%m-%d')} to {to_date_dt.strftime('%Y-%m-%d')}"
                    line_chart = create_stock_line_chart(chart_data, selected_ticker, period_str)
                    st.plotly_chart(line_chart, use_container_width=True)
                    
                    # åŸºæœ¬çµ±è¨ˆæƒ…å ±
                    with st.expander("ğŸ“ˆ æœŸé–“çµ±è¨ˆ"):
                        col1, col2, col3, col4 = st.columns(4)
                        
                        period_return = ((chart_data['Close'].iloc[-1] / chart_data['Close'].iloc[0]) - 1) * 100
                        start_price = chart_data['Close'].iloc[0]
                        end_price = chart_data['Close'].iloc[-1]
                        max_price = chart_data['Close'].max()
                        min_price = chart_data['Close'].min()
                        
                        with col1:
                            st.metric("æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³", f"{period_return:+.2f}%")
                        with col2:
                            st.metric("é–‹å§‹ä¾¡æ ¼", f"{start_price:.2f}")
                        with col3:
                            st.metric("æœ€æ–°ä¾¡æ ¼", f"{end_price:.2f}")
                        with col4:
                            st.metric("æœŸé–“é«˜å€¤/å®‰å€¤", f"{max_price:.2f} / {min_price:.2f}")
                    
                    # Geminiãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†ææ©Ÿèƒ½ï¼ˆãƒãƒ£ãƒ¼ãƒˆã®ä¸‹ã«é…ç½®ï¼‰
                    st.markdown("---")
                    st.markdown("### ğŸ“° éŠ˜æŸ„ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æï¼ˆGemini AIï¼‰")
                    
                    if REPORT_GENERATION_AVAILABLE:
                        # ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æè¨­å®š
                        col1, col2, col3 = st.columns([1, 1, 2])
                        
                        with col1:
                            # ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹æ•°ã®é¸æŠã‚’è¿½åŠ 
                            if 'stock_news_count' not in st.session_state:
                                st.session_state.stock_news_count = 15
                            
                            stock_news_count = st.slider(
                                "å–å¾—è¨˜äº‹æ•°",
                                min_value=0,
                                max_value=100,
                                value=st.session_state.stock_news_count,
                                step=5,
                                help="å–å¾—ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æœ€å¤§æ•°ï¼ˆ0-100ï¼‰",
                                key=f"stock_news_count_slider_{selected_ticker}"
                            )
                            st.session_state.stock_news_count = stock_news_count
                        
                        with col2:
                            if st.button(f"ğŸ” ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æã‚’å®Ÿè¡Œ", type="secondary", key=f"news_analysis_btn_{selected_ticker}"):
                                generate_stock_news_analysis(selected_ticker, from_date_dt, to_date_dt, selected_model, st.session_state.stock_news_count)
                        
                        with col3:
                            st.caption("é¸æŠã—ãŸæœŸé–“ã®éŠ˜æŸ„é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’AIãŒåˆ†æã—ã¾ã™")
                        
                        # å‰å›ã®åˆ†æçµæœãŒã‚ã‚Œã°è‡ªå‹•ã§è¡¨ç¤º
                        analysis_key = f'stock_news_analysis_{selected_ticker}'
                        if analysis_key in st.session_state:
                            st.markdown("#### ğŸ“Š åˆ†æçµæœ")
                            display_stock_news_analysis_result(
                                st.session_state[analysis_key],
                                selected_ticker
                            )
                        else:
                            st.info(f"ğŸ’¡ ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€{selected_ticker}ã®æœŸé–“ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
                    
                    else:
                        missing_components = []
                        if not GEMINI_AVAILABLE:
                            missing_components.append("Gemini API")
                        if not GOOGLE_SEARCH_AVAILABLE:
                            missing_components.append("Google Search API")
                        if not SCRAPING_AVAILABLE:
                            missing_components.append("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒª")
                        st.warning(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†ææ©Ÿèƒ½ã«å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_components)}")
                else:
                    st.error(f"{selected_ticker}ã®æŒ‡å®šæœŸé–“ã®ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    
        except Exception as e:
            display_error_message(e, f"{selected_ticker}ã®ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")


def generate_stock_news_analysis(ticker: str, from_date: datetime, to_date: datetime, model_name: str = "gemini-1.5-pro", news_count: int = 15):
    """å€‹åˆ¥éŠ˜æŸ„ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æã‚’ç”Ÿæˆ"""
    try:
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from modules.google_search import get_financial_news_urls
        from modules.news_scraper import scrape_news_articles
        from modules.gemini_api import GeminiClient, safe_text_processing
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: éŠ˜æŸ„å›ºæœ‰ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢
        with st.spinner(f"{ticker}é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­..."):
            # ä¼æ¥­åã‚’å–å¾—
            try:
                from modules.price_fetcher import cached_get_company_names
                company_names = cached_get_company_names((ticker,))
                company_name = company_names.get(ticker, ticker)
            except:
                company_name = ticker
                
            # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’éŠ˜æŸ„å›ºæœ‰ã«è¨­å®š
            search_topics = [
                f"{ticker} {company_name} æ ªä¾¡",
                f"{ticker} {company_name} æ±ºç®—",
                f"{ticker} {company_name} ãƒ‹ãƒ¥ãƒ¼ã‚¹",
                f"{ticker} æ¥­ç¸¾ ç™ºè¡¨",
                f"{ticker} æ ªå¼ åˆ†æ",
                f"{company_name} ä¼æ¥­ å‹•å‘"
            ]
            
            news_items = get_financial_news_urls(
                start_date=from_date,
                end_date=to_date,
                search_topics=search_topics
            )
            
            if not news_items:
                st.warning(f"{ticker}({company_name})ã«é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æœŸé–“ã‚’èª¿æ•´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                return
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
        with st.spinner(f"{min(len(news_items), news_count)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’å–å¾—ä¸­ï¼ˆæœ€å¤§{news_count}ä»¶ï¼‰..."):
            articles_text = scrape_news_articles(
                news_items=news_items,
                max_articles=news_count,  # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®è¨˜äº‹æ•°
                delay=0.5
            )
            
            if not articles_text or len(articles_text) < 50:
                st.warning("ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                return
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: Gemini APIã§éŠ˜æŸ„åˆ†æã‚’ç”Ÿæˆ
        with st.spinner("AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
            gemini_client = GeminiClient(model_name=model_name)
            
            # éŠ˜æŸ„å›ºæœ‰ã®åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            prompt = create_stock_analysis_prompt(
                ticker=ticker,
                company_name=company_name,
                articles_text=articles_text,
                from_date=from_date,
                to_date=to_date
            )
            
            try:
                safe_prompt = safe_text_processing(prompt)
                response = gemini_client.model.generate_content(
                    safe_prompt,
                    generation_config=gemini_client.generation_config
                )
                
                if response.text:
                    analysis_result = {
                        "success": True,
                        "ticker": ticker,
                        "company_name": company_name,
                        "analysis": safe_text_processing(response.text),
                        "period": f"{from_date.strftime('%Y-%m-%d')} ~ {to_date.strftime('%Y-%m-%d')}",
                        "news_count": len(news_items),
                        "model_used": model_name,
                        "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                    st.session_state[f'stock_news_analysis_{ticker}'] = analysis_result
                    st.success(f"âœ… {ticker}ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    
                else:
                    st.error("AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                    
            except Exception as e:
                st.error(f"AIåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                
    except Exception as e:
        st.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


def create_stock_analysis_prompt(ticker: str, company_name: str, articles_text: str, 
                                from_date: datetime, to_date: datetime) -> str:
    """éŠ˜æŸ„åˆ†æç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
    from modules.gemini_api import safe_text_processing
    
    from_date_str = f"{from_date.year}å¹´{from_date.month}æœˆ{from_date.day}æ—¥"
    to_date_str = f"{to_date.year}å¹´{to_date.month}æœˆ{to_date.day}æ—¥"
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«å‡¦ç†
    safe_articles_text = safe_text_processing(articles_text[:12000])
    
    prompt = f"""ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åŸºã«ã€{ticker}ï¼ˆ{company_name}ï¼‰ã®
{from_date_str}ã‹ã‚‰{to_date_str}ã¾ã§ã®æœŸé–“ã«ãŠã‘ã‚‹ä¼æ¥­åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å¯¾è±¡ä¼æ¥­ã€‘{ticker} - {company_name}
ã€åˆ†ææœŸé–“ã€‘{from_date_str} ï½ {to_date_str}

ã€åé›†ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã€‘
{safe_articles_text}

ã€åˆ†æãƒ¬ãƒãƒ¼ãƒˆè¦ä»¶ã€‘

## 1. æœŸé–“ä¸­ã®ä¸»è¦ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆ300-400å­—ï¼‰
- æ±ºç®—ç™ºè¡¨ã‚„æ¥­ç¸¾äºˆæƒ³ã®å†…å®¹
- æ–°è£½å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ãƒ»äº‹æ¥­ç™ºè¡¨
- çµŒå–¶é™£ã®ç™ºè¨€ã‚„æˆ¦ç•¥ç™ºè¡¨
- M&Aã€ææºã€æŠ•è³‡æ´»å‹•
- ãã®ä»–é‡è¦ãªä¼æ¥­ã‚¤ãƒ™ãƒ³ãƒˆ

## 2. æ ªä¾¡ã«å½±éŸ¿ã‚’ä¸ãˆãŸè¦å› åˆ†æï¼ˆ400-500å­—ï¼‰
- ãƒã‚¸ãƒ†ã‚£ãƒ–è¦å› ï¼ˆæ ªä¾¡æŠ¼ã—ä¸Šã’è¦å› ï¼‰
- ãƒã‚¬ãƒ†ã‚£ãƒ–è¦å› ï¼ˆæ ªä¾¡æŠ¼ã—ä¸‹ã’è¦å› ï¼‰
- å¸‚å ´ã®åå¿œã¨æŠ•è³‡å®¶ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ
- æ¥­ç•Œå…¨ä½“ã®å‹•å‘ã¨ã®é–¢ä¿‚
- ç«¶åˆä»–ç¤¾ã¨ã®æ¯”è¼ƒã«ãŠã‘ã‚‹ä½ç½®ä»˜ã‘

## 3. ä¼æ¥­ã®è²¡å‹™ãƒ»æ¥­ç¸¾åˆ†æï¼ˆ300-400å­—ï¼‰
- å£²ä¸Šé«˜ã€åˆ©ç›Šã®å‹•å‘
- æˆé•·æ€§ã®è©•ä¾¡
- åç›Šæ€§ãƒ»åŠ¹ç‡æ€§ã®å¤‰åŒ–
- ãƒãƒ©ãƒ³ã‚¹ã‚·ãƒ¼ãƒˆã®å¥å…¨æ€§
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼çŠ¶æ³

## 4. ä»Šå¾Œã®å±•æœ›ã¨æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆï¼ˆ300-400å­—ï¼‰
- çŸ­æœŸçš„ï¼ˆ3-6ãƒ¶æœˆï¼‰ãªæ³¨ç›®è¦å› 
- ä¸­é•·æœŸçš„ãªæˆé•·ãƒ‰ãƒ©ã‚¤ãƒãƒ¼
- æ½œåœ¨çš„ãªãƒªã‚¹ã‚¯è¦å› 
- æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ã¨ã®é–¢ä¿‚
- æŠ•è³‡åˆ¤æ–­ã«ãŠã‘ã‚‹è€ƒæ…®äº‹é …

ã€å‡ºåŠ›è¦ä»¶ã€‘
- åˆè¨ˆ1200-1600å­—ç¨‹åº¦
- å®¢è¦³çš„ã§åˆ†æçš„ãªæ–‡ä½“
- ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸå…·ä½“çš„ãªæƒ…å ±ã‚’ç©æ¥µçš„ã«å¼•ç”¨
- æŠ•è³‡æ¨å¥¨ã¯é¿ã‘ã€æƒ…å ±æä¾›ã¨åˆ†æã«å¾¹ã™ã‚‹
- è¦‹å‡ºã—ã‚„æ®µè½ã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã¦èª­ã¿ã‚„ã™ãæ§‹æˆ

ã€é‡è¦äº‹é …ã€‘
- å…·ä½“çš„ãªå£²è²·æ¨å¥¨ã¯ä¸€åˆ‡è¡Œã‚ãªã„
- åˆ†æã¯å‚è€ƒæƒ…å ±ã®æä¾›ã«ç•™ã‚ã‚‹
- æœ€å¾Œã«ã€Œæœ¬åˆ†æã¯æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€ã¨ã„ã†å…è²¬äº‹é …ã‚’è¨˜è¼‰
"""
    
    return prompt


def display_stock_news_analysis_result(analysis_result: Dict[str, Any], ticker: str):
    """éŠ˜æŸ„ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æçµæœã®è¡¨ç¤º"""
    try:
        if not analysis_result.get("success", False):
            st.error(f"åˆ†æçµæœã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {analysis_result.get('error', 'Unknown error')}")
            return
        
        st.markdown(f"### ğŸ“‹ {ticker} AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        
        # ãƒ¬ãƒãƒ¼ãƒˆæ¦‚è¦
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å¯¾è±¡éŠ˜æŸ„", f"{analysis_result.get('ticker', 'N/A')}")
        with col2:
            st.metric("åˆ†ææœŸé–“", analysis_result.get('period', 'N/A'))
        with col3:
            st.metric("å‚ç…§ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°", f"{analysis_result.get('news_count', 0)}ä»¶")
        with col4:
            st.metric("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«", analysis_result.get('model_used', 'N/A'))
        
        st.markdown("---")
        
        # AIåˆ†æå†…å®¹
        analysis_content = analysis_result.get("analysis", "åˆ†æå†…å®¹ãªã—")
        st.markdown(analysis_content)
        
        st.markdown("---")
        
        # ç”Ÿæˆæƒ…å ±
        st.caption(f"ğŸ¤– ç”Ÿæˆæ™‚åˆ»: {analysis_result.get('timestamp', 'N/A')} | ä¼æ¥­å: {analysis_result.get('company_name', 'N/A')}")
        
        # å…è²¬äº‹é …
        st.markdown("### âš ï¸ å…è²¬äº‹é …")
        st.warning("""
        **é‡è¦:** ã“ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã¯æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡æ¨å¥¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
        - AIåˆ†æã¯åé›†ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«åŸºã¥ãå‚è€ƒæƒ…å ±ã§ã™
        - æŠ•è³‡åˆ¤æ–­ã¯å¿…ãšã”è‡ªèº«ã®è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„
        - éå»ã®æƒ…å ±ã‚„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯å°†æ¥ã®çµæœã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“
        - æŠ•è³‡ã«ã¯ãƒªã‚¹ã‚¯ãŒä¼´ã„ã¾ã™ã€‚å°‚é–€å®¶ã¸ã®ç›¸è«‡ã‚’æ¨å¥¨ã—ã¾ã™
        """)
    
    except Exception as e:
        st.error(f"åˆ†æçµæœè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")



def display_investment_report(pnl_df: pd.DataFrame, tickers: List[str]):
    """é‹ç”¨å ±å‘Šã®è¡¨ç¤º"""
    st.subheader("ğŸ“‹ é‹ç”¨å ±å‘Š")
    
    try:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§è¨­å®šã‚’ç®¡ç†
        if 'report_from_date' not in st.session_state:
            st.session_state.report_from_date = datetime.now() - timedelta(days=30)
        if 'report_to_date' not in st.session_state:
            st.session_state.report_to_date = datetime.now()
        if 'report_model' not in st.session_state:
            st.session_state.report_model = "gemini-1.5-pro"
        
        # ä¼æ¥­åã‚’å–å¾—
        if 'company_names_cache' not in st.session_state:
            from modules.price_fetcher import cached_get_company_names
            with show_loading_spinner("ä¼æ¥­åã‚’å–å¾—ä¸­..."):
                st.session_state.company_names_cache = cached_get_company_names(tuple(tickers))
        
        company_names = st.session_state.company_names_cache
        
        # è¨­å®šUI
        st.markdown("### âš™ï¸ åˆ†æè¨­å®š")
        
        col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
        
        with col1:
            from_date = st.date_input(
                "é–‹å§‹æ—¥",
                value=st.session_state.report_from_date.date(),
                help="åˆ†ææœŸé–“ã®é–‹å§‹æ—¥",
                key="report_from_date_input"
            )
            st.session_state.report_from_date = datetime.combine(from_date, datetime.min.time())
        
        with col2:
            to_date = st.date_input(
                "çµ‚äº†æ—¥",
                value=st.session_state.report_to_date.date(),
                help="åˆ†ææœŸé–“ã®çµ‚äº†æ—¥",
                key="report_to_date_input"
            )
            st.session_state.report_to_date = datetime.combine(to_date, datetime.min.time())
        
        with col3:
            model_options = ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-1.0-pro"]
            selected_model = st.selectbox(
                "Geminiãƒ¢ãƒ‡ãƒ«",
                options=model_options,
                index=model_options.index(st.session_state.report_model) if st.session_state.report_model in model_options else 0,
                help="ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
                key="report_model_selector"
            )
            st.session_state.report_model = selected_model
        
        with col4:
            # ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹æ•°ã®é¸æŠã‚’è¿½åŠ 
            if 'report_news_count' not in st.session_state:
                st.session_state.report_news_count = 20
            
            news_count = st.slider(
                "å–å¾—è¨˜äº‹æ•°",
                min_value=0,
                max_value=100,
                value=st.session_state.report_news_count,
                step=5,
                help="å–å¾—ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æœ€å¤§æ•°ï¼ˆ0-100ï¼‰",
                key="report_news_count_slider"
            )
            st.session_state.report_news_count = news_count
        
        # æœŸé–“ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if from_date >= to_date:
            st.error("âš ï¸ é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ã‚ˆã‚Šå‰ã«è¨­å®šã—ã¦ãã ã•ã„")
            return
        
        # ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
        if st.button("ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ", type="primary"):
            with show_loading_spinner("ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æä¸­..."):
                performance_result = analyze_relative_performance(
                    pnl_df, tickers, company_names,
                    st.session_state.report_from_date,
                    st.session_state.report_to_date
                )
                st.session_state.performance_result = performance_result
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœãŒã‚ã‚Œã°è¡¨ç¤º
        if 'performance_result' in st.session_state and st.session_state.performance_result:
            display_relative_performance_analysis(st.session_state.performance_result)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
            if REPORT_GENERATION_AVAILABLE:
                # é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒœã‚¿ãƒ³
                if st.button("ğŸ“‹ é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æä»˜ãï¼‰", type="secondary"):
                    with show_loading_spinner("é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
                        report_result = generate_investment_report(
                            st.session_state.performance_result,
                            st.session_state.report_from_date,
                            st.session_state.report_to_date,
                            selected_model,
                            st.session_state.report_news_count
                        )
                        st.session_state.report_result = report_result
                
                # ãƒ¬ãƒãƒ¼ãƒˆçµæœãŒã‚ã‚Œã°è¡¨ç¤º
                if 'report_result' in st.session_state and st.session_state.report_result:
                    display_investment_report_result(st.session_state.report_result)
            else:
                missing_components = []
                if not GEMINI_AVAILABLE:
                    missing_components.append("Gemini API")
                if not GOOGLE_SEARCH_AVAILABLE:
                    missing_components.append("Google Search API")
                if not SCRAPING_AVAILABLE:
                    missing_components.append("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒª")
                st.warning(f"é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ã«å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_components)}")
        else:
            st.info("ã€Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ã¾ãšç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
            
            # åˆ†æå†…å®¹ã®èª¬æ˜
            with st.expander("ğŸ“‹ é‹ç”¨å ±å‘Šã®å†…å®¹"):
                st.markdown("""
                **ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æï¼š**
                
                - ğŸ“ˆ **å€‹åˆ¥éŠ˜æŸ„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: æœŸé–“å§‹ç‚¹ã‚’100ã¨ã—ãŸç›¸å¯¾æ¨ç§»
                - ğŸ“Š **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“**: ä¿æœ‰æ ªæ•°åŠ é‡ã§ã®ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
                - ğŸ† **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒ**: MSCI ACWIã€NASDAQ100ã€Topix ETFã¨ã®æ¯”è¼ƒ
                - ğŸ“ˆ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«**: å„éŠ˜æŸ„ã®çµ‚å€¤ã¨æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³
                
                **AIé‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆï¼š**
                
                - ğŸŒ **çµŒæ¸ˆãƒ»æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹**: æœŸé–“å†…ã®ä¸»è¦ãªå¸‚å ´ç’°å¢ƒ
                - ğŸ“Š **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªè©•ä¾¡**: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¯¾æ¯”ã§ã®å‹æ•—åˆ†æ
                - â­ **å„ªè‰¯éŠ˜æŸ„åˆ†æ**: ç‰¹ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è‰¯ã‹ã£ãŸéŠ˜æŸ„
                - âš ï¸ **åŠ£å¾ŒéŠ˜æŸ„åˆ†æ**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®åŠ£ã£ãŸéŠ˜æŸ„ã¨ãã®è¦å› 
                
                **å¯¾è±¡éŠ˜æŸ„ï¼š**
                """)
                
                for ticker in tickers:
                    company_name = company_names.get(ticker, ticker)
                    st.markdown(f"- **{ticker}**: {company_name}")
    
    except Exception as e:
        display_error_message(e, "é‹ç”¨å ±å‘Šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")


def analyze_relative_performance(pnl_df: pd.DataFrame, tickers: List[str], company_names: Dict[str, str],
                               from_date: datetime, to_date: datetime) -> Dict[str, Any]:
    """ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ"""
    try:
        from modules.price_fetcher import get_historical_data
        
        # æœŸé–“ã‚’è¨ˆç®—ã—ã¦yfinanceã®æœŸé–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±ºå®šï¼ˆä½™è£•ã‚’æŒãŸã›ã¦å–å¾—ï¼‰
        period_days = (to_date - from_date).days
        if period_days <= 30:
            period = "3mo"  # 1ãƒ¶æœˆåˆ†ã§ã‚‚3ãƒ¶æœˆåˆ†å–å¾—ã—ã¦ç¢ºå®Ÿã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        elif period_days <= 90:
            period = "6mo"
        elif period_days <= 180:
            period = "1y"
        elif period_days <= 365:
            period = "2y"
        else:
            period = "5y"
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ETFã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        benchmark_tickers = ["ACWI", "QQQ", "1348.T"]  # MSCI ACWI, NASDAQ100, Topix ETF
        benchmark_names = {
            "ACWI": "MSCI ACWI ETF",
            "QQQ": "NASDAQ100 ETF", 
            "1348.T": "Topix ETF"
        }
        
        # å…¨ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª + ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰
        all_tickers = tickers + benchmark_tickers
        
        # éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        historical_data = get_historical_data(all_tickers, period)
        
        if historical_data.empty:
            return {"error": "æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"}
        
        # æ¬ æå€¤ã‚’å‰æ—¥ã®å€¤ã§åŸ‹ã‚ã‚‹ï¼ˆffillï¼‰
        historical_data = historical_data.fillna(method='ffill')
        
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’çµ±ä¸€
        if historical_data.index.tz is not None:
            historical_data.index = historical_data.index.tz_localize(None)
        
        # from_dateã¨to_dateã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’å‰Šé™¤
        from_date_naive = from_date.replace(tzinfo=None)
        to_date_naive = to_date.replace(tzinfo=None)
        
        # æŒ‡å®šæœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        mask = (historical_data.index >= from_date_naive) & (historical_data.index <= to_date_naive)
        period_data = historical_data.loc[mask]
        
        if period_data.empty:
            # æœŸé–“ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€ã‚‚è¿‘ã„æ—¥ä»˜ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
            available_dates = historical_data.index
            closest_start = available_dates[available_dates >= from_date_naive]
            
            if len(closest_start) == 0:
                return {"error": f"æŒ‡å®šé–‹å§‹æ—¥ {from_date_naive.strftime('%Y-%m-%d')} ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
            start_date = closest_start[0]
            end_date = min(to_date_naive, available_dates[-1])
            
            mask = (historical_data.index >= start_date) & (historical_data.index <= end_date)
            period_data = historical_data.loc[mask]
            
            if period_data.empty:
                return {"error": "æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        # å®Ÿéš›ã®åˆ†ææœŸé–“ã‚’æ›´æ–°
        actual_start = period_data.index[0]
        actual_end = period_data.index[-1]
        
        # å€‹åˆ¥éŠ˜æŸ„ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®—
        ticker_performance = {}
        for ticker in tickers:
            if ticker in period_data.columns:
                prices = period_data[ticker].fillna(method='ffill')  # å€‹åˆ¥ã«ã‚‚ffillé©ç”¨
                prices = prices.dropna()
                if len(prices) > 0:
                    # å§‹ç‚¹ä¾¡æ ¼ã‚’å–å¾—
                    start_price = prices.iloc[0]
                    
                    # ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ = ãã®æ—¥ã®æ ªä¾¡ / å§‹ç‚¹ã§ã®æ ªä¾¡ * 100
                    normalized = (prices / start_price) * 100
                    
                    # çµ‚å€¤ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
                    end_price = prices.iloc[-1] if len(prices) > 1 else start_price
                    performance_pct = ((end_price / start_price) - 1) * 100
                    
                    ticker_performance[ticker] = {
                        "company_name": company_names.get(ticker, ticker),
                        "normalized_prices": normalized,
                        "end_price": end_price,
                        "performance_pct": performance_pct,
                        "dates": normalized.index,
                        "start_price": start_price,
                        "currency": "æ¤œè¨¼ä¸­"  # determine_currency_from_tickeré–¢æ•°ã¯å¾Œã§å‘¼ã³å‡ºã—
                    }
        
        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®—
        portfolio_performance = calculate_portfolio_performance(pnl_df, period_data, from_date_naive, to_date_naive)
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®—
        benchmark_performance = {}
        for benchmark in benchmark_tickers:
            if benchmark in period_data.columns:
                prices = period_data[benchmark].fillna(method='ffill')  # å€‹åˆ¥ã«ã‚‚ffillé©ç”¨
                prices = prices.dropna()
                if len(prices) > 0:
                    # å§‹ç‚¹ä¾¡æ ¼ã‚’å–å¾—
                    start_price = prices.iloc[0]
                    
                    # ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ = ãã®æ—¥ã®ä¾¡æ ¼ / å§‹ç‚¹ã§ã®ä¾¡æ ¼ * 100
                    normalized = (prices / start_price) * 100
                    
                    # çµ‚å€¤ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
                    end_price = prices.iloc[-1] if len(prices) > 1 else start_price
                    performance_pct = ((end_price / start_price) - 1) * 100
                    
                    benchmark_performance[benchmark] = {
                        "name": benchmark_names[benchmark],
                        "normalized_prices": normalized,
                        "performance_pct": performance_pct,
                        "dates": normalized.index,
                        "start_price": start_price
                    }
        
        return {
            "success": True,
            "period": f"{actual_start.strftime('%Y-%m-%d')} - {actual_end.strftime('%Y-%m-%d')}",
            "requested_period": f"{from_date_naive.strftime('%Y-%m-%d')} - {to_date_naive.strftime('%Y-%m-%d')}",
            "ticker_performance": ticker_performance,
            "portfolio_performance": portfolio_performance,
            "benchmark_performance": benchmark_performance,
            "period_data": period_data
        }
    
    except Exception as e:
        return {"error": f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"}


def calculate_portfolio_performance(pnl_df: pd.DataFrame, period_data: pd.DataFrame, 
                                  from_date: datetime, to_date: datetime) -> Dict[str, Any]:
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨ˆç®—ï¼ˆç‚ºæ›¿æ›ç®—å«ã‚€ï¼‰"""
    try:
        from modules.price_fetcher import cached_get_exchange_rates, determine_currency_from_ticker, convert_to_jpy
        
        # ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        exchange_rates = cached_get_exchange_rates()
        
        # æ ªæ•°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        shares_data = {}
        for _, row in pnl_df.iterrows():
            ticker = row['ticker']
            shares = row['shares']
            shares_data[ticker] = shares
        
        # ffillã‚’é©ç”¨ã—ãŸperiod_dataã‚’ä½¿ç”¨
        period_data_filled = period_data.fillna(method='ffill')
        
        # å„æ—¥ä»˜ã§ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¾¡å€¤ã‚’è¨ˆç®—ï¼ˆå††æ›ç®—ï¼‰
        portfolio_values_jpy = []
        valid_dates = []
        debug_info = []
        
        for date, row in period_data_filled.iterrows():
            total_value_jpy = 0
            valid_tickers = 0
            daily_debug = {"date": date, "tickers": {}}
            
            for ticker, shares in shares_data.items():
                if ticker in period_data_filled.columns and not pd.isna(row[ticker]):
                    # ç¾åœ°é€šè²¨ã§ã®æ ªä¾¡
                    price_local = row[ticker]
                    
                    # é€šè²¨ã‚’åˆ¤å®š
                    currency = determine_currency_from_ticker(ticker)
                    
                    # å††æ›ç®—
                    price_jpy = convert_to_jpy(price_local, currency, exchange_rates)
                    
                    # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¾¡å€¤ã«è¿½åŠ 
                    value_jpy = price_jpy * shares
                    total_value_jpy += value_jpy
                    valid_tickers += 1
                    
                    daily_debug["tickers"][ticker] = {
                        "price_local": price_local,
                        "currency": currency,
                        "price_jpy": price_jpy,
                        "shares": shares,
                        "value_jpy": value_jpy
                    }
            
            # å°‘ãªãã¨ã‚‚1éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¿½åŠ 
            if valid_tickers > 0:
                portfolio_values_jpy.append(total_value_jpy)
                valid_dates.append(date)
                daily_debug["total_value_jpy"] = total_value_jpy
                debug_info.append(daily_debug)
        
        if len(portfolio_values_jpy) > 0:
            # å§‹ç‚¹ä¾¡å€¤ã‚’å–å¾—
            start_value = portfolio_values_jpy[0]
            
            # ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ = ãã®æ—¥ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå††æ›ç®—é¡ / å§‹ç‚¹ã§ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå††æ›ç®—é¡ * 100
            normalized_values = [(value / start_value) * 100 for value in portfolio_values_jpy]
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®—
            end_value = portfolio_values_jpy[-1] if len(portfolio_values_jpy) > 1 else start_value
            performance_pct = ((end_value / start_value) - 1) * 100
            
            return {
                "normalized_values": normalized_values,
                "performance_pct": performance_pct,
                "dates": valid_dates,
                "raw_values": portfolio_values_jpy,
                "start_value": start_value,
                "end_value": end_value,
                "debug_info": debug_info[:5]  # æœ€åˆã®5æ—¥åˆ†ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            }
        else:
            return {"error": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}
    
    except Exception as e:
        return {"error": f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}"}


def display_relative_performance_analysis(performance_result: Dict[str, Any]):
    """ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æçµæœã®è¡¨ç¤º"""
    try:
        if not performance_result.get("success", False):
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {performance_result.get('error', 'Unknown error')}")
            return
        
        st.markdown("### ğŸ“ˆ ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æçµæœ")
        
        # æœŸé–“æƒ…å ±ã‚’è¡¨ç¤º
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"**å®Ÿéš›ã®åˆ†ææœŸé–“:** {performance_result['period']}")
        with col2:
            if 'requested_period' in performance_result:
                st.markdown(f"**è¦æ±‚æœŸé–“:** {performance_result['requested_period']}")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚°ãƒ©ãƒ•ã®ä½œæˆ
        fig = go.Figure()
        
        # Yè»¸ã®ç¯„å›²ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ã™ã¹ã¦ã®å€¤ã‚’åé›†
        all_values = []
        
        # å€‹åˆ¥éŠ˜æŸ„ã®ã‚°ãƒ©ãƒ•
        ticker_performance = performance_result["ticker_performance"]
        for ticker, data in ticker_performance.items():
            normalized_values = data["normalized_prices"].values
            all_values.extend(normalized_values)
            
            fig.add_trace(go.Scatter(
                x=data["dates"],
                y=normalized_values,
                mode='lines',
                name=f"{ticker} ({data['company_name']})",
                line=dict(width=2),
                hovertemplate=f'<b>{ticker}</b><br>æ—¥ä»˜: %{{x}}<br>ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: %{{y:.2f}}<extra></extra>'
            ))
        
        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã®ã‚°ãƒ©ãƒ•
        portfolio_data = performance_result["portfolio_performance"]
        if "normalized_values" in portfolio_data:
            portfolio_values = portfolio_data["normalized_values"]
            all_values.extend(portfolio_values)
            
            fig.add_trace(go.Scatter(
                x=portfolio_data["dates"],
                y=portfolio_values,
                mode='lines',
                name="ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“",
                line=dict(width=4, color='red'),
                hovertemplate='<b>ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“</b><br>æ—¥ä»˜: %{x}<br>ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: %{y:.2f}<extra></extra>'
            ))
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚°ãƒ©ãƒ•
        benchmark_performance = performance_result["benchmark_performance"]
        colors = ["orange", "green", "purple"]
        for i, (benchmark, data) in enumerate(benchmark_performance.items()):
            benchmark_values = data["normalized_prices"].values
            all_values.extend(benchmark_values)
            
            fig.add_trace(go.Scatter(
                x=data["dates"],
                y=benchmark_values,
                mode='lines',
                name=data["name"],
                line=dict(width=3, dash='dash', color=colors[i % len(colors)]),
                hovertemplate=f'<b>{data["name"]}</b><br>æ—¥ä»˜: %{{x}}<br>ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: %{{y:.2f}}<extra></extra>'
            ))
        
        # Yè»¸ã®ç¯„å›²ã‚’è¨ˆç®—
        if all_values:
            min_val = min(all_values)
            max_val = max(all_values)
            y_range = max_val - min_val
            y_padding = y_range * 0.05  # 5%ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            y_min = max(0, min_val - y_padding)  # 0ä»¥ä¸‹ã«ã¯ã—ãªã„
            y_max = max_val + y_padding
        else:
            y_min, y_max = 95, 105  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¯„å›²
        
        fig.update_layout(
            title="ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¨ç§»ï¼ˆæœŸé–“å§‹ç‚¹=100ï¼‰",
            xaxis_title="æ—¥ä»˜",
            yaxis_title="ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
            yaxis=dict(
                range=[y_min, y_max],
                tickformat=".1f"
            ),
            height=600,
            hovermode='x unified',
            showlegend=True
        )
        
        # 100ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ 
        fig.add_hline(y=100, line_dash="dot", line_color="gray", annotation_text="ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ (100)")
        
        # ã‚°ãƒ©ãƒ•ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        with st.expander("ğŸ“Š ã‚°ãƒ©ãƒ•ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
            st.write(f"**Yè»¸ç¯„å›²:** {y_min:.2f} - {y_max:.2f}")
            st.write(f"**å…¨ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°:** {len(all_values)}")
            if all_values:
                st.write(f"**æœ€å°å€¤:** {min(all_values):.2f}")
                st.write(f"**æœ€å¤§å€¤:** {max(all_values):.2f}")
                st.write(f"**100å‘¨è¾ºã®å€¤ã®ç¢ºèª:**")
                around_100 = [v for v in all_values if 95 <= v <= 105]
                st.write(f"- 95-105ã®ç¯„å›²ã®å€¤æ•°: {len(around_100)}")
                
                # å€‹åˆ¥éŠ˜æŸ„ã®æ­£è¦åŒ–ç¢ºèª
                st.write("**å€‹åˆ¥éŠ˜æŸ„ã®æ­£è¦åŒ–ç¢ºèª:**")
                for ticker, data in list(ticker_performance.items())[:3]:
                    prices = data["normalized_prices"]
                    st.write(f"- {ticker}: é–‹å§‹å€¤={prices.iloc[0]:.2f}, çµ‚äº†å€¤={prices.iloc[-1]:.2f}, ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°={len(prices)}")
                
                # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ­£è¦åŒ–ç¢ºèª
                if "normalized_values" in portfolio_data:
                    pf_values = portfolio_data["normalized_values"]
                    st.write(f"**ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª:** é–‹å§‹å€¤={pf_values[0]:.2f}, çµ‚äº†å€¤={pf_values[-1]:.2f}, ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°={len(pf_values)}")
                
                # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ­£è¦åŒ–ç¢ºèª
                st.write("**ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ­£è¦åŒ–ç¢ºèª:**")
                for benchmark, data in benchmark_performance.items():
                    prices = data["normalized_prices"]
                    st.write(f"- {data['name']}: é–‹å§‹å€¤={prices.iloc[0]:.2f}, çµ‚äº†å€¤={prices.iloc[-1]:.2f}")
                    
                # å®Ÿéš›ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«
                st.write("**å…ƒãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ï¼ˆperiod_dataï¼‰:**")
                if not performance_result["period_data"].empty:
                    sample_data = performance_result["period_data"].head(3)
                    st.dataframe(sample_data)
        
        fig.update_xaxes(showgrid=True)
        fig.update_yaxes(showgrid=True)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
        st.markdown("### ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«")
        
        table_data = []
        
        # å€‹åˆ¥éŠ˜æŸ„
        for ticker, data in ticker_performance.items():
            table_data.append({
                "ç¨®åˆ¥": "å€‹åˆ¥éŠ˜æŸ„",
                "éŠ˜æŸ„/ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯": f"{ticker} ({data['company_name']})",
                "çµ‚å€¤": f"{data['end_price']:.2f}",
                "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)": data['performance_pct'],  # æ•°å€¤ã¨ã—ã¦ä¿å­˜
                "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³è¡¨ç¤º": f"{data['performance_pct']:+.2f}%"
            })
        
        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“
        if "performance_pct" in portfolio_data:
            table_data.append({
                "ç¨®åˆ¥": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª",
                "éŠ˜æŸ„/ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“",
                "çµ‚å€¤": "-",
                "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)": portfolio_data['performance_pct'],  # æ•°å€¤ã¨ã—ã¦ä¿å­˜
                "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³è¡¨ç¤º": f"{portfolio_data['performance_pct']:+.2f}%"
            })
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
        for benchmark, data in benchmark_performance.items():
            table_data.append({
                "ç¨®åˆ¥": "ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯",
                "éŠ˜æŸ„/ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯": data["name"],
                "çµ‚å€¤": "-",
                "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)": data['performance_pct'],  # æ•°å€¤ã¨ã—ã¦ä¿å­˜
                "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³è¡¨ç¤º": f"{data['performance_pct']:+.2f}%"
            })
        
        table_df = pd.DataFrame(table_data)
        
        # è¡¨ç¤ºç”¨ã«ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼ˆæ•°å€¤ã§ã‚½ãƒ¼ãƒˆï¼‰
        display_df = table_df.copy()
        display_df = display_df.sort_values("æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)", ascending=False)  # é™é †ã§ã‚½ãƒ¼ãƒˆ
        
        # è¡¨ç¤ºç”¨åˆ—ã®ã¿ã‚’é¸æŠ
        display_df_formatted = display_df[["ç¨®åˆ¥", "éŠ˜æŸ„/ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", "çµ‚å€¤", "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³è¡¨ç¤º"]].copy()
        display_df_formatted.columns = ["ç¨®åˆ¥", "éŠ˜æŸ„/ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", "çµ‚å€¤", "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³"]
        
        # æ•°å€¤ã‚½ãƒ¼ãƒˆç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
        sortable_df = table_df[["ç¨®åˆ¥", "éŠ˜æŸ„/ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", "çµ‚å€¤", "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)"]].copy()
        sortable_df.columns = ["ç¨®åˆ¥", "éŠ˜æŸ„/ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", "çµ‚å€¤", "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)"]
        
        # ã‚½ãƒ¼ãƒˆå¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦è¡¨ç¤º
        st.dataframe(
            sortable_df, 
            use_container_width=True,
            column_config={
                "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)": st.column_config.NumberColumn(
                    "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)",
                    help="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆæ•°å€¤ã‚½ãƒ¼ãƒˆå¯èƒ½ï¼‰",
                    format="%.2f"
                )
            }
        )
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
        with st.expander("ğŸ” è©³ç´°ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
            st.write("**ãƒ†ãƒ¼ãƒ–ãƒ«ã‚½ãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿:**")
            debug_df = table_df[["éŠ˜æŸ„/ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)", "æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³è¡¨ç¤º"]].copy()
            debug_df = debug_df.sort_values("æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³(%)", ascending=False)
            st.dataframe(debug_df)
            
            st.write("**å€‹åˆ¥éŠ˜æŸ„è¨ˆç®—è©³ç´°:**")
            for ticker, data in ticker_performance.items():
                st.write(f"**{ticker}**:")
                st.write(f"- é–‹å§‹ä¾¡æ ¼: {data.get('start_price', 'N/A'):.2f}")
                st.write(f"- çµ‚äº†ä¾¡æ ¼: {data.get('end_price', 'N/A'):.2f}")
                st.write(f"- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {data.get('performance_pct', 'N/A'):.2f}%")
                if 'normalized_prices' in data:
                    first_5 = data['normalized_prices'].head(5).values
                    st.write(f"- æœ€åˆã®5ã¤ã®æ­£è¦åŒ–å€¤: {first_5}")
            
            st.write("**ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªè¨ˆç®—è©³ç´°:**")
            if "debug_info" in portfolio_data:
                for i, debug_day in enumerate(portfolio_data["debug_info"]):
                    st.write(f"**æ—¥ä»˜ {i+1}: {debug_day['date'].strftime('%Y-%m-%d')}**")
                    st.write(f"- ç·ä¾¡å€¤: Â¥{debug_day['total_value_jpy']:,.0f}")
                    for ticker, info in debug_day["tickers"].items():
                        st.write(f"  - {ticker}: {info['price_local']:.2f} {info['currency']} â†’ Â¥{info['price_jpy']:.2f} Ã— {info['shares']} = Â¥{info['value_jpy']:,.0f}")
            
            st.write("**ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¨ˆç®—è©³ç´°:**")
            for benchmark, data in benchmark_performance.items():
                st.write(f"**{data['name']}**:")
                st.write(f"- é–‹å§‹ä¾¡æ ¼: {data.get('start_price', 'N/A'):.2f}")
                st.write(f"- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {data.get('performance_pct', 'N/A'):.2f}%")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼
        st.markdown("### ğŸ† ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼")
        
        if "performance_pct" in portfolio_data:
            portfolio_return = portfolio_data["performance_pct"]
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³", f"{portfolio_return:+.2f}%")
            
            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒï¼ˆMSCI ACWIã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
            if benchmark_performance:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯MSCI ACWI
                default_benchmark = "ACWI" if "ACWI" in benchmark_performance else list(benchmark_performance.keys())[0]
                
                with col2:
                    acwi_data = benchmark_performance.get(default_benchmark)
                    if acwi_data:
                        acwi_return = acwi_data["performance_pct"]
                        outperformance = portfolio_return - acwi_return
                        st.metric(
                            f"vs {acwi_data['name']}",
                            f"{outperformance:+.2f}%",
                            delta=f"{'å‹' if outperformance > 0 else 'è² '}"
                        )
                
                with col3:
                    avg_benchmark_return = sum(data["performance_pct"] for data in benchmark_performance.values()) / len(benchmark_performance)
                    vs_avg = portfolio_return - avg_benchmark_return
                    st.metric(
                        "vs ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¹³å‡",
                        f"{vs_avg:+.2f}%",
                        delta=f"{'å‹' if vs_avg > 0 else 'è² '}"
                    )
    
    except Exception as e:
        st.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")


def generate_investment_report(performance_result: Dict[str, Any], from_date: datetime, 
                             to_date: datetime, model: str = "gemini-1.5-pro", news_count: int = 20) -> Dict[str, Any]:
    """Gemini APIã¨Google Search APIã‚’ä½¿ç”¨ã—ã¦é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    try:
        if not REPORT_GENERATION_AVAILABLE:
            missing_components = []
            if not GEMINI_AVAILABLE:
                missing_components.append("Gemini API")
            if not GOOGLE_SEARCH_AVAILABLE:
                missing_components.append("Google Search API")
            if not SCRAPING_AVAILABLE:
                missing_components.append("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒª")
            
            return {
                "success": False,
                "error": f"å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {', '.join(missing_components)}",
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from modules.google_search import get_financial_news_urls
        from modules.news_scraper import scrape_news_articles
        from modules.gemini_api import generate_gemini_investment_report
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹URLã‚’æ¤œç´¢
        with st.spinner("é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­..."):
            news_items = get_financial_news_urls(
                start_date=from_date,
                end_date=to_date,
                search_topics=[
                    "ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡‘èå¸‚å ´ å‹•å‘",
                    "æ ªå¼å¸‚å ´ æ—¥çµŒå¹³å‡ ãƒ€ã‚¦ ãƒŠã‚¹ãƒ€ãƒƒã‚¯",
                    "ç‚ºæ›¿å¸‚å ´ ãƒ‰ãƒ«å†† ãƒ¦ãƒ¼ãƒ­ãƒ‰ãƒ«",
                    "ä¸­å¤®éŠ€è¡Œ é‡‘èæ”¿ç­– FRB ECB æ—¥éŠ€",
                    "çµŒæ¸ˆæŒ‡æ¨™ ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ é›‡ç”¨çµ±è¨ˆ GDP",
                    "å‚µåˆ¸å¸‚å ´ é‡‘åˆ© ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–",
                    "ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£å¸‚å ´ åŸæ²¹ é‡‘ å•†å“",
                    "åœ°æ”¿å­¦ãƒªã‚¹ã‚¯ å›½éš›æƒ…å‹¢"
                ]
            )
            
            if not news_items:
                return {
                    "success": False,
                    "error": "ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æœŸé–“ã‚’èª¿æ•´ã—ã¦ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                    "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
        with st.spinner(f"{min(len(news_items), news_count)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’å–å¾—ä¸­ï¼ˆæœ€å¤§{news_count}ä»¶ï¼‰..."):
            articles_text = scrape_news_articles(
                news_items=news_items,
                max_articles=news_count,  # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®è¨˜äº‹æ•°
                delay=0.5  # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚0.5ç§’å¾…æ©Ÿ
            )
            
            if not articles_text or len(articles_text) < 100:
                return {
                    "success": False,
                    "error": "ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                    "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: Gemini APIã§è¦ç´„ã‚’ç”Ÿæˆ
        with st.spinner("AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
            report_result = generate_gemini_investment_report(
                performance_result=performance_result,
                from_date=from_date,
                to_date=to_date,
                news_articles_text=articles_text,
                model_name=model
            )
        
        return report_result
    
    except Exception as e:
        logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "success": False,
            "error": f"é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }


def create_performance_summary(portfolio_performance: Dict[str, Any], benchmark_performance: Dict[str, Any], 
                             ticker_performance: Dict[str, Any], from_date: datetime, to_date: datetime) -> str:
    """è©³ç´°ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
    summary_parts = []
    
    # æœŸé–“æƒ…å ±
    summary_parts.append(f"ã€åˆ†ææœŸé–“ã€‘{from_date.strftime('%Y-%m-%d')} - {to_date.strftime('%Y-%m-%d')} ({(to_date - from_date).days}æ—¥é–“)")
    
    # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°
    if "performance_pct" in portfolio_performance:
        portfolio_return = portfolio_performance["performance_pct"]
        summary_parts.append(f"\nã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã€‘")
        summary_parts.append(f"ç·åˆãƒªã‚¿ãƒ¼ãƒ³: {portfolio_return:+.2f}%")
        
        if "start_value" in portfolio_performance and "end_value" in portfolio_performance:
            start_val = portfolio_performance["start_value"]
            end_val = portfolio_performance["end_value"]
            summary_parts.append(f"æœŸé–“é–‹å§‹æ™‚ä¾¡å€¤: Â¥{start_val:,.0f}")
            summary_parts.append(f"æœŸé–“çµ‚äº†æ™‚ä¾¡å€¤: Â¥{end_val:,.0f}")
            summary_parts.append(f"ä¾¡å€¤å¤‰å‹•é¡: Â¥{end_val - start_val:+,.0f}")
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒè©³ç´°
    if benchmark_performance:
        summary_parts.append(f"\nã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒã€‘")
        for benchmark, data in benchmark_performance.items():
            bench_return = data['performance_pct']
            vs_portfolio = portfolio_return - bench_return if "performance_pct" in portfolio_performance else 0
            summary_parts.append(f"- {data['name']}: {bench_return:+.2f}% (vs ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª: {vs_portfolio:+.2f}%)")
    
    # å€‹åˆ¥éŠ˜æŸ„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°
    if ticker_performance:
        summary_parts.append(f"\nã€å€‹åˆ¥éŠ˜æŸ„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘")
        summary_parts.append(f"ç·éŠ˜æŸ„æ•°: {len(ticker_performance)}éŠ˜æŸ„")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_tickers = sorted(ticker_performance.items(), key=lambda x: x[1]['performance_pct'], reverse=True)
        
        # å‹ç‡è¨ˆç®—
        positive_count = sum(1 for _, data in sorted_tickers if data['performance_pct'] > 0)
        win_rate = (positive_count / len(sorted_tickers)) * 100
        summary_parts.append(f"å‹ç‡: {win_rate:.1f}% ({positive_count}/{len(sorted_tickers)}éŠ˜æŸ„ãŒãƒ—ãƒ©ã‚¹)")
        
        # å…¨éŠ˜æŸ„ãƒªã‚¹ãƒˆ
        summary_parts.append(f"\nã€å…¨éŠ˜æŸ„ãƒªã‚¿ãƒ¼ãƒ³ä¸€è¦§ã€‘")
        for ticker, data in sorted_tickers:
            summary_parts.append(f"- {ticker} ({data['company_name']}): {data['performance_pct']:+.2f}%")
        
        # ä¸Šä½5éŠ˜æŸ„è©³ç´°
        top_5 = sorted_tickers[:5]
        summary_parts.append(f"\nã€ä¸Šä½5éŠ˜æŸ„è©³ç´°ã€‘")
        for i, (ticker, data) in enumerate(top_5, 1):
            summary_parts.append(f"{i}ä½. {ticker} ({data['company_name']})")
            summary_parts.append(f"   ãƒªã‚¿ãƒ¼ãƒ³: {data['performance_pct']:+.2f}%")
            summary_parts.append(f"   é–‹å§‹ä¾¡æ ¼: {data['start_price']:.2f} {data.get('currency', 'USD')}")
            summary_parts.append(f"   çµ‚äº†ä¾¡æ ¼: {data['end_price']:.2f} {data.get('currency', 'USD')}")
        
        # ä¸‹ä½5éŠ˜æŸ„è©³ç´°
        bottom_5 = sorted_tickers[-5:] if len(sorted_tickers) >= 5 else sorted_tickers[-len(sorted_tickers):]
        bottom_5.reverse()  # ä¸‹ä½ã‹ã‚‰é †ã«è¡¨ç¤º
        summary_parts.append(f"\nã€ä¸‹ä½5éŠ˜æŸ„è©³ç´°ã€‘")
        for i, (ticker, data) in enumerate(bottom_5, 1):
            summary_parts.append(f"{i}ä½. {ticker} ({data['company_name']})")
            summary_parts.append(f"   ãƒªã‚¿ãƒ¼ãƒ³: {data['performance_pct']:+.2f}%")
            summary_parts.append(f"   é–‹å§‹ä¾¡æ ¼: {data['start_price']:.2f} {data.get('currency', 'USD')}")
            summary_parts.append(f"   çµ‚äº†ä¾¡æ ¼: {data['end_price']:.2f} {data.get('currency', 'USD')}")
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        returns = [data['performance_pct'] for data in ticker_performance.values()]
        if returns:
            import statistics
            summary_parts.append(f"\nã€éŠ˜æŸ„ãƒªã‚¿ãƒ¼ãƒ³çµ±è¨ˆã€‘")
            summary_parts.append(f"å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³: {statistics.mean(returns):+.2f}%")
            summary_parts.append(f"ä¸­å¤®å€¤ãƒªã‚¿ãƒ¼ãƒ³: {statistics.median(returns):+.2f}%")
            summary_parts.append(f"æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³: {max(returns):+.2f}%")
            summary_parts.append(f"æœ€å°ãƒªã‚¿ãƒ¼ãƒ³: {min(returns):+.2f}%")
            summary_parts.append(f"ãƒªã‚¿ãƒ¼ãƒ³æ¨™æº–åå·®: {statistics.stdev(returns):.2f}%")
    
    return "\n".join(summary_parts)


def create_investment_report_prompt(performance_summary: str, from_date: datetime, to_date: datetime) -> str:
    """é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
    
    prompt = f"""ä»¥ä¸‹ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€åŒ…æ‹¬çš„ãªé‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã€‘
{performance_summary}

ã€ãƒ¬ãƒãƒ¼ãƒˆæ§‹æˆã¨è©³ç´°è¦ä»¶ã€‘

## 1. å¸‚å ´ç’°å¢ƒåˆ†æï¼ˆ800-1000å­—ï¼‰
{from_date.strftime('%Y-%m-%d')}ã‹ã‚‰{to_date.strftime('%Y-%m-%d')}ã®æœŸé–“ã«ãŠã‘ã‚‹åŒ…æ‹¬çš„ãªå¸‚å ´ç’°å¢ƒåˆ†æï¼š

### çµŒæ¸ˆãƒ»é‡‘èæ”¿ç­–
- ä¸»è¦ä¸­å¤®éŠ€è¡Œï¼ˆFRBã€ECBã€æ—¥éŠ€ç­‰ï¼‰ã®é‡‘èæ”¿ç­–å‹•å‘
- ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ã€é›‡ç”¨çµ±è¨ˆã€GDPæˆé•·ç‡ç­‰ã®ä¸»è¦çµŒæ¸ˆæŒ‡æ¨™
- é‡‘åˆ©ç’°å¢ƒã®å¤‰åŒ–ã¨ãã®å¸‚å ´ã¸ã®å½±éŸ¿

### æ”¿æ²»ãƒ»åœ°æ”¿å­¦ãƒªã‚¹ã‚¯
- ä¸»è¦å›½ã®æ”¿æ²»æƒ…å‹¢ï¼ˆç±³å›½ã€æ¬§å·ã€æ—¥æœ¬ã€ä¸­å›½ç­‰ï¼‰
- å›½éš›çš„ãªæ”¿æ²»ãƒ»å¤–äº¤å•é¡Œ
- åœ°æ”¿å­¦çš„ç·Šå¼µã¨ãã®å¸‚å ´ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ

### å¸‚å ´ãƒ†ãƒ¼ãƒã¨ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ
- æœŸé–“ä¸­ã®ä¸»è¦ãªå¸‚å ´ãƒ†ãƒ¼ãƒï¼ˆAIã€ã‚¨ãƒãƒ«ã‚®ãƒ¼è»¢æ›ã€ã‚¤ãƒ³ãƒ•ãƒ¬ç­‰ï¼‰
- æŠ•è³‡å®¶ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã®å¤‰åŒ–
- ã‚»ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®å‹•å‘

## 2. ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°è©•ä¾¡ï¼ˆ600-800å­—ï¼‰

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒåˆ†æ
- MSCI ACWI ETFã€NASDAQ100 ETFã€Topix ETFã¨ã®è©³ç´°æ¯”è¼ƒ
- å„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®å‹æ•—è¦å› åˆ†æ
- ãƒªã‚¹ã‚¯èª¿æ•´å¾Œãƒªã‚¿ãƒ¼ãƒ³ï¼ˆã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªçš„è¦³ç‚¹ï¼‰ã®è©•ä¾¡
- ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ç‰¹å¾´ï¼ˆæˆé•·æ ªvsä¾¡å€¤æ ªã€åœ°åŸŸé…åˆ†ç­‰ï¼‰ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆãŸå½±éŸ¿

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦å› åˆ†æ
- å¸‚å ´ç’°å¢ƒå¤‰åŒ–ãŒãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«ä¸ãˆãŸå½±éŸ¿
- ã‚»ã‚¯ã‚¿ãƒ¼é…åˆ†åŠ¹æœã€éŠ˜æŸ„é¸æŠåŠ¹æœã®åˆ†æ
- é€šè²¨è¦å› ã®å½±éŸ¿ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

## 3. å€‹åˆ¥éŠ˜æŸ„è©³ç´°åˆ†æï¼ˆ800-1000å­—ï¼‰

### ä¸Šä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹éŠ˜æŸ„ï¼ˆä¸Šä½5éŠ˜æŸ„ï¼‰
å„éŠ˜æŸ„ã«ã¤ã„ã¦ä»¥ä¸‹ã‚’åˆ†æï¼š
- æœŸé–“ä¸­ã®ä¸»è¦ãªä¼æ¥­ç™ºè¡¨ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹
- æ±ºç®—å†…å®¹ã€æ¥­ç¸¾äºˆæƒ³ã®å¤‰åŒ–
- ã‚»ã‚¯ã‚¿ãƒ¼ãƒ»æ¥­ç•Œå‹•å‘ã¨ã®é–¢ä¿‚
- æ ªä¾¡ä¸Šæ˜‡ã®å…·ä½“çš„è¦å› 

### ä¸‹ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹éŠ˜æŸ„ï¼ˆä¸‹ä½5éŠ˜æŸ„ï¼‰
å„éŠ˜æŸ„ã«ã¤ã„ã¦ä»¥ä¸‹ã‚’åˆ†æï¼š
- æœŸé–“ä¸­ã®æ‡¸å¿µææ–™ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹
- æ±ºç®—ãƒŸã‚¹ã€æ¥­ç¸¾ä¸‹æ–¹ä¿®æ­£ç­‰ã®è¦å› 
- æ¥­ç•Œé€†é¢¨ã€ç«¶åˆç’°å¢ƒã®å¤‰åŒ–
- æ ªä¾¡ä¸‹è½ã®å…·ä½“çš„è¦å› 

## 4. ä»Šå¾Œã®æŠ•è³‡æˆ¦ç•¥ã¸ã®ç¤ºå”†ï¼ˆ400-600å­—ï¼‰

### å¸‚å ´å±•æœ›
- ç¾åœ¨ã®å¸‚å ´ç’°å¢ƒã®æŒç¶šæ€§
- æ³¨æ„ã™ã¹ããƒªã‚¹ã‚¯è¦å› 
- æ–°ãŸãªæŠ•è³‡æ©Ÿä¼šã®å¯èƒ½æ€§

### ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªé‹å–¶ã¸ã®ç¤ºå”†
- ç¾åœ¨ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å¼·ã¿ãƒ»å¼±ã¿
- å¸‚å ´ç’°å¢ƒå¤‰åŒ–ã¸ã®å¯¾å¿œç­–ï¼ˆä¸€èˆ¬è«–ã¨ã—ã¦ï¼‰
- ãƒªã‚¹ã‚¯ç®¡ç†ã®è¦³ç‚¹ã‹ã‚‰ã®ç•™æ„ç‚¹

ã€å‡ºåŠ›è¦ä»¶ã€‘
- åˆè¨ˆ2000-3000å­—ç¨‹åº¦ã®è©³ç´°ãªåˆ†æ
- å®¢è¦³çš„ã§å°‚é–€çš„ãªæ–‡ä½“
- ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå…·ä½“çš„ãªåˆ†æ
- æŠ•è³‡æ¨å¥¨ã¯é¿ã‘ã€æƒ…å ±æä¾›ã¨åˆ†æã«å¾¹ã™ã‚‹
- è¦‹å‡ºã—ã‚„æ®µè½ã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã¦èª­ã¿ã‚„ã™ãæ§‹æˆ

æ³¨æ„äº‹é …: 
- å…·ä½“çš„ãªå£²è²·æ¨å¥¨ã¯ä¸€åˆ‡è¡Œã‚ãªã„
- ä¸€èˆ¬çš„ãªå¸‚å ´åˆ†æã¨æƒ…å ±æä¾›ã«ç•™ã‚ã‚‹
- å…è²¬äº‹é …ã¨ã—ã¦ã€Œéå»ã®å®Ÿç¸¾ã¯å°†æ¥ã‚’ä¿è¨¼ã—ãªã„ã€æ—¨ã‚’æœ€å¾Œã«è¨˜è¼‰"""
    
    return prompt


def display_investment_report_result(report_result: Dict[str, Any]):
    """é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆçµæœã®è¡¨ç¤º"""
    try:
        if not report_result.get("success", False):
            st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {report_result.get('error', 'Unknown error')}")
            return
        
        st.markdown("### ğŸ“‹ AIé‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆ")
        
        # ãƒ¬ãƒãƒ¼ãƒˆæ¦‚è¦
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«", report_result.get("model_used", "N/A"))
        with col2:
            st.metric("ç”Ÿæˆæ™‚åˆ»", report_result.get("timestamp", "N/A"))
        
        st.markdown("---")
        
        # AIãƒ¬ãƒãƒ¼ãƒˆå†…å®¹
        report_content = report_result.get("report", "ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ãªã—")
        st.markdown(report_content)
        
        st.markdown("---")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼
        with st.expander("ğŸ“Š è©³ç´°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿"):
            performance_summary = report_result.get("performance_summary", "ãƒ‡ãƒ¼ã‚¿ãªã—")
            st.text(performance_summary)
        
        # å…è²¬äº‹é …
        st.markdown("### âš ï¸ å…è²¬äº‹é …")
        st.warning("""
        **é‡è¦:** ã“ã®é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆã¯æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡æ¨å¥¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
        - AIåˆ†æã¯ä¸€èˆ¬çš„ãªæƒ…å ±ã¨å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå‚è€ƒæƒ…å ±ã§ã™
        - æŠ•è³‡åˆ¤æ–­ã¯å¿…ãšã”è‡ªèº«ã®è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„
        - éå»ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯å°†æ¥ã®çµæœã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“
        - å°‚é–€å®¶ã¸ã®ç›¸è«‡ã‚’æ¨å¥¨ã—ã¾ã™
        """)
    
    except Exception as e:
        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")


# å¤ã„é–¢æ•°ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸï¼ˆæ–°ã—ã„é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã«ç½®ãæ›ãˆï¼‰


def fetch_portfolio_news(tickers: List[str], days: int, max_per_ticker: int) -> List[Dict[str, Any]]:
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªéŠ˜æŸ„ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
    try:
        import requests
        import feedparser
        import time
    except ImportError as e:
        st.error(f"å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
        st.info("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        st.code("pip install feedparser requests")
        return []
    
    all_articles = []
    
    for ticker in tickers:
        try:
            # æ ªä¾¡é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€é«˜å“è³ªãªã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
            stock_keywords = ["stock", "shares", "earnings", "revenue", "profit", "quarterly", "financial", "results", "guidance", "outlook", "analyst", "rating", "price target", "upgrade", "downgrade"]
            
            # è¤‡æ•°ã®ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œ
            queries = [
                f'"{ticker}" AND (earnings OR revenue OR "quarterly results")',
                f'"{ticker}" AND (stock OR shares OR "price target")',
                f'"{ticker}" AND (analyst OR rating OR upgrade OR downgrade)'
            ]
            
            import urllib.parse
            # æœ€åˆã®ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ï¼ˆæœ€ã‚‚é–¢é€£æ€§ãŒé«˜ã„ï¼‰
            encoded_query = urllib.parse.quote(f'{queries[0]} when:{days}d')
            # è‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹å„ªå…ˆï¼ˆUS market focusï¼‰
            url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en&gl=US&ceid=US:en"
            
            # RSSå–å¾—
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                feed = feedparser.parse(response.content)
                
                articles_count = 0
                for entry in feed.entries:
                    if articles_count >= max_per_ticker:
                        break
                    
                    # è¨˜äº‹æƒ…å ±ã‚’æŠ½å‡º
                    title = getattr(entry, 'title', 'No Title')
                    summary = getattr(entry, 'summary', '')
                    
                    # æ ªä¾¡é–¢é€£æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                    if not is_stock_relevant(title, summary, ticker):
                        continue
                    
                    # ä¿¡é ¼ã§ãã‚‹é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã‹ãƒã‚§ãƒƒã‚¯
                    source = getattr(entry.source, 'title', 'Unknown') if hasattr(entry, 'source') else 'Google News'
                    if not is_credible_financial_source(source):
                        continue
                    
                    article = {
                        'ticker': ticker,
                        'title': title,
                        'link': getattr(entry, 'link', ''),
                        'published': getattr(entry, 'published', ''),
                        'summary': summary,
                        'source': source
                    }
                    
                    # å…¬é–‹æ—¥æ™‚ã‚’è§£æ
                    if article['published']:
                        try:
                            from email.utils import parsedate_to_datetime
                            article['published_dt'] = parsedate_to_datetime(article['published'])
                        except:
                            article['published_dt'] = datetime.now(timezone.utc)
                    else:
                        article['published_dt'] = datetime.now(timezone.utc)
                    
                    all_articles.append(article)
                    articles_count += 1
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆ1ç§’é–“éš”ï¼‰
            time.sleep(1)
            
        except Exception as e:
            st.warning(f"{ticker}ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            continue
    
    return all_articles


def is_stock_relevant(title: str, summary: str, ticker: str) -> bool:
    """è¨˜äº‹ãŒæ ªä¾¡ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    
    # æ ªä¾¡é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    stock_keywords = [
        # æ¥­ç¸¾ãƒ»æ±ºç®—é–¢é€£
        'earnings', 'revenue', 'profit', 'sales', 'quarterly', 'annual', 'results', 
        'guidance', 'outlook', 'forecast', 'beat', 'miss', 'consensus',
        
        # æ ªä¾¡ãƒ»è©•ä¾¡é–¢é€£
        'stock', 'shares', 'price', 'target', 'rating', 'upgrade', 'downgrade',
        'buy', 'sell', 'hold', 'analyst', 'analysts', 'recommendation',
        
        # ä¼æ¥­æ´»å‹•é–¢é€£
        'merger', 'acquisition', 'partnership', 'deal', 'agreement', 'contract',
        'product', 'launch', 'announcement', 'ceo', 'executive', 'management',
        
        # è²¡å‹™é–¢é€£
        'dividend', 'split', 'buyback', 'debt', 'cash', 'investment',
        'valuation', 'market cap', 'financial', 'balance sheet',
        
        # è¦åˆ¶ãƒ»æ¥­ç•Œé–¢é€£
        'fda', 'approval', 'regulation', 'lawsuit', 'settlement', 'compliance'
    ]
    
    # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ ªä¾¡ã«é–¢ä¿‚ãªã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
    exclude_keywords = [
        'sports', 'entertainment', 'celebrity', 'movie', 'music', 'fashion',
        'weather', 'politics', 'election', 'social media', 'personal life',
        'charity', 'donation', 'award', 'festival', 'event', 'party'
    ]
    
    content = (title + ' ' + summary).lower()
    
    # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ç„¡é–¢ä¿‚
    for keyword in exclude_keywords:
        if keyword in content:
            return False
    
    # ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    ticker_mentioned = ticker.lower() in content or ticker.replace('.T', '').lower() in content
    
    # æ ªä¾¡é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    stock_related = any(keyword in content for keyword in stock_keywords)
    
    # ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã¨æ ªä¾¡é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸¡æ–¹ãŒå¿…è¦
    return ticker_mentioned and stock_related


def is_credible_financial_source(source: str) -> bool:
    """ä¿¡é ¼ã§ãã‚‹é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã‹ãƒã‚§ãƒƒã‚¯"""
    
    # ä¿¡é ¼ã§ãã‚‹é‡‘èãƒ»ãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹
    credible_sources = [
        # Tier 1: æœ€é«˜å“è³ªã®é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹
        'Reuters', 'Bloomberg', 'Financial Times', 'Wall Street Journal', 'WSJ',
        'Associated Press', 'AP News',
        
        # Tier 2: ä¸»è¦ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ‡ã‚£ã‚¢
        'CNBC', 'MarketWatch', 'Yahoo Finance', 'Barron\'s', 'Fortune', 'Forbes',
        'Business Insider', 'Benzinga', 'TheStreet', 'Seeking Alpha',
        
        # Tier 3: å°‚é–€é‡‘èãƒ¡ãƒ‡ã‚£ã‚¢
        'Morningstar', 'Zacks', 'InvestorPlace', 'Motley Fool', 'TipRanks',
        'Finviz', 'GuruFocus', 'Simply Wall St',
        
        # Tier 4: ä¸€èˆ¬ãƒ¡ãƒ‡ã‚£ã‚¢ã®ãƒ“ã‚¸ãƒã‚¹éƒ¨é–€
        'CNN Business', 'BBC Business', 'CNBC', 'Fox Business',
        'The Guardian Business', 'New York Times Business'
    ]
    
    if not source or source == 'Unknown':
        return False
    
    source_lower = source.lower()
    
    # å®Œå…¨ä¸€è‡´ã¾ãŸã¯éƒ¨åˆ†ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    for credible in credible_sources:
        if credible.lower() in source_lower or source_lower in credible.lower():
            return True
    
    # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ™ãƒ¼ã‚¹ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯
    financial_domains = [
        'reuters.com', 'bloomberg.com', 'ft.com', 'wsj.com', 'cnbc.com',
        'marketwatch.com', 'finance.yahoo.com', 'barrons.com',
        'fortune.com', 'forbes.com', 'businessinsider.com'
    ]
    
    for domain in financial_domains:
        if domain in source_lower:
            return True
    
    return False


def get_sample_news_data(tickers: List[str]) -> List[Dict[str, Any]]:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    
    sample_articles = []
    
    sample_news_templates = [
        {
            'title_template': '{ticker} Reports Q3 Earnings Beat, Revenue Up 15% YoY',
            'summary': 'The company exceeded analyst expectations with strong quarterly results, driving investor optimism for future growth prospects.',
            'source': 'Reuters'
        },
        {
            'title_template': '{ticker} Stock Surges on New Product Launch Announcement',
            'summary': 'Shares jumped in after-hours trading following the unveiling of innovative products expected to capture significant market share.',
            'source': 'Bloomberg'
        },
        {
            'title_template': 'Analysts Raise {ticker} Price Target, Maintain Buy Rating',
            'summary': 'Multiple investment firms upgraded their outlook citing improved fundamentals and strong competitive positioning in key markets.',
            'source': 'CNBC'
        },
        {
            'title_template': '{ticker} Announces Strategic Partnership with Industry Leader',
            'summary': 'The collaboration is expected to accelerate growth initiatives and enhance the company\'s technological capabilities.',
            'source': 'MarketWatch'
        },
        {
            'title_template': '{ticker} CEO Provides Upbeat Guidance for Next Quarter',
            'summary': 'Management expressed confidence in maintaining growth momentum, citing strong demand trends and operational efficiency improvements.',
            'source': 'Yahoo Finance'
        },
        {
            'title_template': '{ticker} Dividend Increase Signals Management Confidence',
            'summary': 'The board approved a 12% dividend hike, reflecting strong cash generation and optimistic outlook for sustainable returns.',
            'source': 'Barron\'s'
        },
        {
            'title_template': 'FDA Approval Boosts {ticker} Stock in Premarket Trading',
            'summary': 'Regulatory clearance for the company\'s key product removes a major overhang and opens new revenue opportunities.',
            'source': 'Seeking Alpha'
        },
        {
            'title_template': '{ticker} Stock Upgraded to Overweight by Goldman Sachs',
            'summary': 'The investment bank cited improving market conditions and the company\'s strong execution on strategic initiatives.',
            'source': 'Financial Times'
        }
    ]
    
    for i, ticker in enumerate(tickers):
        for j, template in enumerate(sample_news_templates[:3]):  # å„éŠ˜æŸ„3è¨˜äº‹ã¾ã§
            article = {
                'ticker': ticker,
                'title': template['title_template'].format(ticker=ticker),
                'summary': template['summary'],
                'source': template['source'],
                'link': f'https://example.com/news/{ticker.lower()}-{j+1}',
                'published': f'{(datetime.now() - timedelta(hours=j*6+i)).strftime("%a, %d %b %Y %H:%M:%S")} GMT',
                'published_dt': datetime.now(timezone.utc) - timedelta(hours=j*6+i)
            }
            sample_articles.append(article)
    
    return sample_articles


def render_news_articles(articles: List[Dict[str, Any]], pnl_df: pd.DataFrame):
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’è¡¨ç¤º"""
    if not articles:
        st.warning("ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    st.subheader(f"ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ ({len(articles)}ä»¶)")
    
    # éŠ˜æŸ„åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    ticker_articles = {}
    for article in articles:
        ticker = article['ticker']
        if ticker not in ticker_articles:
            ticker_articles[ticker] = []
        ticker_articles[ticker].append(article)
    
    # é‡è¦åº¦é †ã§ã‚½ãƒ¼ãƒˆï¼ˆæ™‚é–“é †ï¼‰
    for ticker in ticker_articles:
        ticker_articles[ticker].sort(key=lambda x: x.get('published_dt', datetime.now(timezone.utc)), reverse=True)
    
    # è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
    col1, col2 = st.columns([3, 1])
    with col1:
        st.write("**è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³:**")
    with col2:
        show_all = st.checkbox("å…¨éŠ˜æŸ„ã‚’å±•é–‹è¡¨ç¤º", value=False)
    
    # éŠ˜æŸ„åˆ¥ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¡¨ç¤º
    for ticker, ticker_news in ticker_articles.items():
        # éŠ˜æŸ„ã®æ™‚ä¾¡ç·é¡ã‚’å–å¾—ï¼ˆé‡è¦åº¦ã®å‚è€ƒï¼‰
        ticker_value = 0
        if not pnl_df.empty:
            ticker_row = pnl_df[pnl_df['ticker'] == ticker]
            if not ticker_row.empty:
                ticker_value = ticker_row.iloc[0]['current_value_jpy']
        
        value_display = format_currency(ticker_value) if ticker_value > 0 else "ãƒ‡ãƒ¼ã‚¿ãªã—"
        
        if show_all:
            # å±•é–‹è¡¨ç¤º
            st.subheader(f"ğŸ“ˆ {ticker} ({len(ticker_news)}ä»¶) - è©•ä¾¡é¡: {value_display}")
            render_ticker_news_expanded(ticker_news)
        else:
            # æŠ˜ã‚ŠãŸãŸã¿è¡¨ç¤º
            with st.expander(f"ğŸ“ˆ {ticker} ({len(ticker_news)}ä»¶) - è©•ä¾¡é¡: {value_display}"):
                render_ticker_news_expanded(ticker_news)


def render_ticker_news_expanded(articles: List[Dict[str, Any]]):
    """éŠ˜æŸ„ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å±•é–‹è¡¨ç¤º"""
    for i, article in enumerate(articles):
        # è¨˜äº‹ã®å¹´é½¢ã‚’è¨ˆç®—
        age = "ä¸æ˜"
        if article.get('published_dt'):
            time_diff = datetime.now(timezone.utc) - article['published_dt']
            if time_diff.days > 0:
                age = f"{time_diff.days}æ—¥å‰"
            elif time_diff.seconds >= 3600:
                hours = time_diff.seconds // 3600
                age = f"{hours}æ™‚é–“å‰"
            elif time_diff.seconds >= 60:
                minutes = time_diff.seconds // 60
                age = f"{minutes}åˆ†å‰"
            else:
                age = "ãŸã£ãŸä»Š"
        
        # è¨˜äº‹ã‚«ãƒ¼ãƒ‰
        with st.container():
            col1, col2, col3 = st.columns([6, 2, 1])
            
            with col1:
                st.write(f"**{article['title']}**")
                if article.get('summary'):
                    st.write(article['summary'])
                if article.get('link'):
                    st.write(f"[è¨˜äº‹ã‚’èª­ã‚€]({article['link']})")
            
            with col2:
                st.write(f"**å‡ºå…¸:** {article.get('source', 'Unknown')}")
                st.write(f"**æŠ•ç¨¿:** {age}")
            
            with col3:
                # é‡è¦åº¦ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼ˆè‹±èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯¾å¿œï¼‰
                title_lower = article['title'].lower()
                summary_lower = article.get('summary', '').lower()
                content = title_lower + ' ' + summary_lower
                
                importance = "ğŸ“°"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                
                # æœ€é«˜é‡è¦åº¦: æ±ºç®—ãƒ»æ¥­ç¸¾ãƒ»æ ªä¾¡æ€¥å¤‰
                high_impact_keywords = ['earnings', 'revenue', 'beat', 'miss', 'guidance', 'upgrade', 'downgrade', 'surge', 'plunge', 'target', 'rating']
                if any(keyword in content for keyword in high_impact_keywords):
                    importance = "ğŸ”¥"
                # é«˜é‡è¦åº¦: è£½å“ãƒ»ææºãƒ»M&Aãƒ»è¦åˆ¶
                elif any(keyword in content for keyword in ['launch', 'partnership', 'merger', 'acquisition', 'fda', 'approval', 'deal', 'agreement', 'ceo']):
                    importance = "â­"
                # ä¸­é‡è¦åº¦: ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ»æŠ•è³‡å®¶é–¢é€£
                elif any(keyword in content for keyword in ['analyst', 'buy', 'sell', 'hold', 'recommendation', 'dividend', 'split']):
                    importance = "ğŸ“Š"
                
                st.write(f"**é‡è¦åº¦**")
                st.write(importance)
            
            st.markdown("---")


def display_welcome_page():
    """ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒšãƒ¼ã‚¸ã®è¡¨ç¤º"""
    st.markdown("""
    ## ğŸ‘‹ ã‚ˆã†ã“ãï¼
    
    ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ ªå¼ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ç®¡ç†ã¨åˆ†æã‚’è¡Œã†ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
    
    ### ğŸš€ æ©Ÿèƒ½
    - **CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆ**: ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã®ç°¡å˜ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ ªä¾¡**: Yahoo Financeã‹ã‚‰ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—
    - **æç›Šè¨ˆç®—**: å¤šé€šè²¨å¯¾å¿œã®ç²¾å¯†ãªæç›Šè¨ˆç®—
    - **ãƒªã‚¹ã‚¯åˆ†æ**: VaRã€CVaRã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç­‰ã®è¨ˆç®—
    - **å¯è¦–åŒ–**: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒ£ãƒ¼ãƒˆã¨ã‚°ãƒ©ãƒ•
    
    ### ğŸ“‹ ä½¿ç”¨æ–¹æ³•
    1. å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    2. ãƒ‡ãƒ¼ã‚¿ãŒè‡ªå‹•çš„ã«åˆ†æã•ã‚Œã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    3. å„ã‚¿ãƒ–ã§è©³ç´°ãªåˆ†æçµæœã‚’ç¢ºèªã§ãã¾ã™
    
    ### ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
    ```
    Ticker,Shares,AvgCostJPY
    AAPL,100,15000
    MSFT,50,25000
    7203.T,1000,800
    ```
    
    å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼
    """)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    sample_data = {
        'Ticker': ['AAPL', 'MSFT', '7203.T', 'ASML', 'TSLA'],
        'Shares': [100, 50, 1000, 20, 30],
        'AvgCostJPY': [15000, 25000, 800, 60000, 20000]
    }
    sample_df = pd.DataFrame(sample_data)
    sample_csv = sample_df.to_csv(index=False)
    
    st.download_button(
        label="ğŸ“¥ ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=sample_csv,
        file_name="sample_portfolio.csv",
        mime="text/csv"
    )


if __name__ == "__main__":
    main_dashboard()