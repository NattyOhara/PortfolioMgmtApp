"""
æ±ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
å…±é€šçš„ã«ä½¿ç”¨ã•ã‚Œã‚‹æ©Ÿèƒ½
"""

import pandas as pd
import numpy as np
import streamlit as st
from typing import Any, Dict, List, Optional, Union
import logging
from datetime import datetime, timedelta
import time

logger = logging.getLogger(__name__)


def format_currency(amount: float, currency: str = 'JPY') -> str:
    """
    é€šè²¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    
    Args:
        amount: é‡‘é¡
        currency: é€šè²¨ã‚³ãƒ¼ãƒ‰
    
    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿é€šè²¨æ–‡å­—åˆ—
    """
    try:
        if currency == 'JPY':
            return f"Â¥{amount:,.0f}"
        elif currency == 'USD':
            return f"${amount:,.2f}"
        elif currency == 'EUR':
            return f"â‚¬{amount:,.2f}"
        elif currency == 'GBP':
            return f"Â£{amount:,.2f}"
        else:
            return f"{amount:,.2f} {currency}"
    except:
        return f"{amount} {currency}"


def format_percentage(value: float, decimal_places: int = 2) -> str:
    """
    ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    
    Args:
        value: ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸å€¤
        decimal_places: å°æ•°ç‚¹ä»¥ä¸‹æ¡æ•°
    
    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸æ–‡å­—åˆ—
    """
    try:
        if value > 0:
            return f"+{value:.{decimal_places}f}%"
        else:
            return f"{value:.{decimal_places}f}%"
    except:
        return f"{value}%"


def safe_divide(numerator: float, denominator: float, default: float = 0.0) -> float:
    """
    å®‰å…¨ãªé™¤ç®—ï¼ˆã‚¼ãƒ­é™¤ç®—å›é¿ï¼‰
    
    Args:
        numerator: åˆ†å­
        denominator: åˆ†æ¯
        default: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    Returns:
        float: é™¤ç®—çµæœã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    """
    try:
        if denominator == 0 or pd.isna(denominator):
            return default
        return numerator / denominator
    except:
        return default


def calculate_returns(prices: pd.Series) -> pd.Series:
    """
    ä¾¡æ ¼ç³»åˆ—ã‹ã‚‰ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‚’è¨ˆç®—
    
    Args:
        prices: ä¾¡æ ¼ç³»åˆ—
    
    Returns:
        pd.Series: ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—
    """
    try:
        return prices.pct_change().dropna()
    except Exception as e:
        logger.error(f"ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return pd.Series()


def calculate_cumulative_returns(returns: pd.Series) -> pd.Series:
    """
    ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—
    
    Args:
        returns: ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—
    
    Returns:
        pd.Series: ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—
    """
    try:
        return (1 + returns).cumprod() - 1
    except Exception as e:
        logger.error(f"ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return pd.Series()


def handle_missing_data(df: pd.DataFrame, method: str = 'drop') -> pd.DataFrame:
    """
    æ¬ æãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
    
    Args:
        df: DataFrame
        method: å‡¦ç†æ–¹æ³• ('drop', 'forward_fill', 'backward_fill')
    
    Returns:
        pd.DataFrame: å‡¦ç†æ¸ˆã¿DataFrame
    """
    try:
        if method == 'drop':
            return df.dropna()
        elif method == 'forward_fill':
            return df.fillna(method='ffill')
        elif method == 'backward_fill':
            return df.fillna(method='bfill')
        else:
            return df
    except Exception as e:
        logger.error(f"æ¬ æãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return df


def validate_dataframe(df: pd.DataFrame, required_columns: List[str]) -> bool:
    """
    DataFrameã®æ¤œè¨¼
    
    Args:
        df: æ¤œè¨¼ã™ã‚‹DataFrame
        required_columns: å¿…é ˆåˆ—ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        bool: æ¤œè¨¼çµæœ
    """
    try:
        if df.empty:
            return False
        
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.warning(f"ä¸è¶³ã—ã¦ã„ã‚‹åˆ—: {missing_columns}")
            return False
        
        return True
    except Exception as e:
        logger.error(f"DataFrameæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


def create_date_range(start_date: str, end_date: str, freq: str = 'D') -> pd.DatetimeIndex:
    """
    æ—¥ä»˜ç¯„å›²ã‚’ä½œæˆ
    
    Args:
        start_date: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        end_date: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        freq: é »åº¦ï¼ˆ'D', 'B', 'M'ç­‰ï¼‰
    
    Returns:
        pd.DatetimeIndex: æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    """
    try:
        return pd.date_range(start=start_date, end=end_date, freq=freq)
    except Exception as e:
        logger.error(f"æ—¥ä»˜ç¯„å›²ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return pd.DatetimeIndex([])


def get_business_days_between(start_date: datetime, end_date: datetime) -> int:
    """
    å–¶æ¥­æ—¥æ•°ã‚’è¨ˆç®—
    
    Args:
        start_date: é–‹å§‹æ—¥
        end_date: çµ‚äº†æ—¥
    
    Returns:
        int: å–¶æ¥­æ—¥æ•°
    """
    try:
        business_days = pd.bdate_range(start=start_date, end=end_date)
        return len(business_days)
    except Exception as e:
        logger.error(f"å–¶æ¥­æ—¥æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return 0


def retry_operation(func, max_retries: int = 3, delay: float = 1.0):
    """
    ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãæ“ä½œå®Ÿè¡Œ
    
    Args:
        func: å®Ÿè¡Œã™ã‚‹é–¢æ•°
        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
        delay: ãƒªãƒˆãƒ©ã‚¤é–“éš”ï¼ˆç§’ï¼‰
    
    Returns:
        Any: é–¢æ•°ã®å®Ÿè¡Œçµæœ
    """
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if attempt == max_retries - 1:
                logger.error(f"æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°åˆ°é”: {str(e)}")
                raise e
            else:
                logger.warning(f"ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries}: {str(e)}")
                time.sleep(delay)


def log_performance(func):
    """
    é–¢æ•°å®Ÿè¡Œæ™‚é–“ã‚’ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
    
    Args:
        func: å¯¾è±¡é–¢æ•°
    
    Returns:
        é–¢æ•°: ãƒ©ãƒƒãƒ—ã—ãŸé–¢æ•°
    """
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            end_time = time.time()
            logger.info(f"{func.__name__} å®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
            return result
        except Exception as e:
            end_time = time.time()
            logger.error(f"{func.__name__} ã‚¨ãƒ©ãƒ¼ï¼ˆå®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’ï¼‰: {str(e)}")
            raise e
    return wrapper


def display_dataframe_info(df: pd.DataFrame, title: str = "DataFrameæƒ…å ±"):
    """
    DataFrameã®æƒ…å ±ã‚’è¡¨ç¤º
    
    Args:
        df: è¡¨ç¤ºã™ã‚‹DataFrame
        title: ã‚¿ã‚¤ãƒˆãƒ«
    """
    try:
        with st.expander(f"ğŸ“Š {title}"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("è¡Œæ•°", len(df))
            
            with col2:
                st.metric("åˆ—æ•°", len(df.columns))
            
            with col3:
                memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024
                st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡", f"{memory_usage:.2f} MB")
            
            if not df.empty:
                st.subheader("ãƒ‡ãƒ¼ã‚¿å‹")
                dtype_df = pd.DataFrame({
                    'åˆ—å': df.columns,
                    'ãƒ‡ãƒ¼ã‚¿å‹': df.dtypes.values,
                    'æ¬ æå€¤æ•°': df.isnull().sum().values
                })
                st.dataframe(dtype_df, use_container_width=True)
    except Exception as e:
        logger.error(f"DataFrameæƒ…å ±è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")


def create_download_link(df: pd.DataFrame, filename: str, link_text: str = "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
    """
    DataFrameã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ
    
    Args:
        df: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹DataFrame
        filename: ãƒ•ã‚¡ã‚¤ãƒ«å
        link_text: ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆ
    """
    try:
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label=f"ğŸ“¥ {link_text}",
            data=csv,
            file_name=filename,
            mime="text/csv"
        )
    except Exception as e:
        logger.error(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")


def show_loading_spinner(text: str = "å‡¦ç†ä¸­..."):
    """
    ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ãƒ”ãƒŠãƒ¼ã‚’è¡¨ç¤º
    
    Args:
        text: è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆ
    """
    return st.spinner(text)


def display_error_message(error: Exception, context: str = ""):
    """
    ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    
    Args:
        error: ã‚¨ãƒ©ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        context: ã‚¨ãƒ©ãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    """
    error_msg = f"{context}: {str(error)}" if context else str(error)
    st.error(f"âš ï¸ {error_msg}")
    logger.error(error_msg)


def display_success_message(message: str):
    """
    æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    
    Args:
        message: è¡¨ç¤ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    st.success(f"âœ… {message}")
    logger.info(message)


def display_warning_message(message: str):
    """
    è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    
    Args:
        message: è¡¨ç¤ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    st.warning(f"âš ï¸ {message}")
    logger.warning(message)


def display_info_message(message: str):
    """
    æƒ…å ±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    
    Args:
        message: è¡¨ç¤ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    st.info(f"â„¹ï¸ {message}")
    logger.info(message)


def get_color_palette(n_colors: int) -> List[str]:
    """
    ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆã‚’å–å¾—
    
    Args:
        n_colors: å¿…è¦ãªè‰²æ•°
    
    Returns:
        List[str]: è‰²ã®ãƒªã‚¹ãƒˆ
    """
    import plotly.colors as pc
    
    if n_colors <= 10:
        return pc.qualitative.Plotly[:n_colors]
    else:
        # è‰²æ•°ãŒå¤šã„å ´åˆã¯ç¹°ã‚Šè¿”ã—
        base_colors = pc.qualitative.Plotly
        return (base_colors * ((n_colors // len(base_colors)) + 1))[:n_colors]


def calculate_correlation_significance(corr_matrix: pd.DataFrame, n_observations: int) -> pd.DataFrame:
    """
    ç›¸é–¢ä¿‚æ•°ã®æœ‰æ„æ€§ã‚’è¨ˆç®—
    
    Args:
        corr_matrix: ç›¸é–¢è¡Œåˆ—
        n_observations: è¦³æ¸¬æ•°
    
    Returns:
        pd.DataFrame: æœ‰æ„æ€§ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆTrue/Falseï¼‰
    """
    try:
        from scipy import stats
        
        # tçµ±è¨ˆé‡ã‚’è¨ˆç®—
        t_stat = corr_matrix * np.sqrt((n_observations - 2) / (1 - corr_matrix**2))
        
        # på€¤ã‚’è¨ˆç®—
        p_values = 2 * (1 - stats.t.cdf(np.abs(t_stat), n_observations - 2))
        
        # 5%æ°´æº–ã§æœ‰æ„ã‹ã©ã†ã‹
        significant = p_values < 0.05
        
        return significant
    except Exception as e:
        logger.error(f"ç›¸é–¢æœ‰æ„æ€§è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return pd.DataFrame()


def clean_numeric_data(series: pd.Series) -> pd.Series:
    """
    æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    
    Args:
        series: æ•°å€¤ç³»åˆ—
    
    Returns:
        pd.Series: ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ç³»åˆ—
    """
    try:
        # æ•°å€¤ä»¥å¤–ã‚’é™¤å»
        numeric_series = pd.to_numeric(series, errors='coerce')
        
        # ç„¡é™å¤§å€¤ã‚’é™¤å»
        numeric_series = numeric_series.replace([np.inf, -np.inf], np.nan)
        
        # ç•°å¸¸å€¤æ¤œå‡ºï¼ˆ3ã‚·ã‚°ãƒãƒ«ãƒ¼ãƒ«ï¼‰
        if len(numeric_series.dropna()) > 0:
            mean_val = numeric_series.mean()
            std_val = numeric_series.std()
            
            if std_val > 0:
                outlier_mask = (np.abs(numeric_series - mean_val) > 3 * std_val)
                numeric_series[outlier_mask] = np.nan
        
        return numeric_series
    except Exception as e:
        logger.error(f"æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return series